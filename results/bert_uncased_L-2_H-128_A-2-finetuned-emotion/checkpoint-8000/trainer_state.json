{
  "best_global_step": 8000,
  "best_metric": 0.9075,
  "best_model_checkpoint": "./results/bert_uncased_L-2_H-128_A-2-finetuned-emotion\\checkpoint-8000",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 3.5950865745544434,
      "learning_rate": 4.969375e-05,
      "loss": 1.6748,
      "step": 50
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1733031272888184,
      "learning_rate": 4.9381250000000004e-05,
      "loss": 1.5954,
      "step": 100
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.636943817138672,
      "learning_rate": 4.9068750000000003e-05,
      "loss": 1.5918,
      "step": 150
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.269495964050293,
      "learning_rate": 4.875625e-05,
      "loss": 1.5613,
      "step": 200
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.5293610095977783,
      "learning_rate": 4.844375e-05,
      "loss": 1.5431,
      "step": 250
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.7815486192703247,
      "learning_rate": 4.813125e-05,
      "loss": 1.5344,
      "step": 300
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.291375160217285,
      "learning_rate": 4.781875e-05,
      "loss": 1.5195,
      "step": 350
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.043148994445801,
      "learning_rate": 4.750625e-05,
      "loss": 1.4299,
      "step": 400
    },
    {
      "epoch": 0.45,
      "grad_norm": 4.063982963562012,
      "learning_rate": 4.7193750000000005e-05,
      "loss": 1.3255,
      "step": 450
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.004897117614746,
      "learning_rate": 4.6881250000000005e-05,
      "loss": 1.2834,
      "step": 500
    },
    {
      "epoch": 0.55,
      "grad_norm": 8.737518310546875,
      "learning_rate": 4.656875e-05,
      "loss": 1.2335,
      "step": 550
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.959628582000732,
      "learning_rate": 4.625625e-05,
      "loss": 1.1443,
      "step": 600
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.854074478149414,
      "learning_rate": 4.594375e-05,
      "loss": 1.1644,
      "step": 650
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.224806308746338,
      "learning_rate": 4.563125e-05,
      "loss": 1.0422,
      "step": 700
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.1632490158081055,
      "learning_rate": 4.531875000000001e-05,
      "loss": 1.0411,
      "step": 750
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.9631218910217285,
      "learning_rate": 4.500625e-05,
      "loss": 1.0059,
      "step": 800
    },
    {
      "epoch": 0.85,
      "grad_norm": 11.470327377319336,
      "learning_rate": 4.469375e-05,
      "loss": 0.9012,
      "step": 850
    },
    {
      "epoch": 0.9,
      "grad_norm": 7.1638641357421875,
      "learning_rate": 4.4381250000000005e-05,
      "loss": 0.9318,
      "step": 900
    },
    {
      "epoch": 0.95,
      "grad_norm": 8.006437301635742,
      "learning_rate": 4.4068750000000004e-05,
      "loss": 0.9269,
      "step": 950
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.2938714027404785,
      "learning_rate": 4.375625e-05,
      "loss": 0.8659,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.768,
      "eval_f1_score": 0.768,
      "eval_loss": 0.7571026086807251,
      "eval_runtime": 7.857,
      "eval_samples_per_second": 254.55,
      "eval_steps_per_second": 15.909,
      "step": 1000
    },
    {
      "epoch": 1.05,
      "grad_norm": 4.304599761962891,
      "learning_rate": 4.344375e-05,
      "loss": 0.8005,
      "step": 1050
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.054678440093994,
      "learning_rate": 4.313125e-05,
      "loss": 0.7565,
      "step": 1100
    },
    {
      "epoch": 1.15,
      "grad_norm": 7.033719539642334,
      "learning_rate": 4.281875e-05,
      "loss": 0.7345,
      "step": 1150
    },
    {
      "epoch": 1.2,
      "grad_norm": 5.431650161743164,
      "learning_rate": 4.250625e-05,
      "loss": 0.7299,
      "step": 1200
    },
    {
      "epoch": 1.25,
      "grad_norm": 8.1795654296875,
      "learning_rate": 4.2193750000000006e-05,
      "loss": 0.7214,
      "step": 1250
    },
    {
      "epoch": 1.3,
      "grad_norm": 4.120092391967773,
      "learning_rate": 4.188125e-05,
      "loss": 0.701,
      "step": 1300
    },
    {
      "epoch": 1.35,
      "grad_norm": 14.986201286315918,
      "learning_rate": 4.1568750000000004e-05,
      "loss": 0.6524,
      "step": 1350
    },
    {
      "epoch": 1.4,
      "grad_norm": 12.727551460266113,
      "learning_rate": 4.125625e-05,
      "loss": 0.6652,
      "step": 1400
    },
    {
      "epoch": 1.45,
      "grad_norm": 7.284477710723877,
      "learning_rate": 4.094375e-05,
      "loss": 0.681,
      "step": 1450
    },
    {
      "epoch": 1.5,
      "grad_norm": 10.149630546569824,
      "learning_rate": 4.063125e-05,
      "loss": 0.6133,
      "step": 1500
    },
    {
      "epoch": 1.55,
      "grad_norm": 6.880110263824463,
      "learning_rate": 4.031875e-05,
      "loss": 0.5893,
      "step": 1550
    },
    {
      "epoch": 1.6,
      "grad_norm": 8.730254173278809,
      "learning_rate": 4.000625e-05,
      "loss": 0.566,
      "step": 1600
    },
    {
      "epoch": 1.65,
      "grad_norm": 9.568562507629395,
      "learning_rate": 3.969375e-05,
      "loss": 0.6207,
      "step": 1650
    },
    {
      "epoch": 1.7,
      "grad_norm": 10.546320915222168,
      "learning_rate": 3.9381250000000005e-05,
      "loss": 0.5599,
      "step": 1700
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.9800812005996704,
      "learning_rate": 3.9068750000000004e-05,
      "loss": 0.5669,
      "step": 1750
    },
    {
      "epoch": 1.8,
      "grad_norm": 9.278825759887695,
      "learning_rate": 3.875625e-05,
      "loss": 0.5807,
      "step": 1800
    },
    {
      "epoch": 1.85,
      "grad_norm": 9.212529182434082,
      "learning_rate": 3.844375e-05,
      "loss": 0.6024,
      "step": 1850
    },
    {
      "epoch": 1.9,
      "grad_norm": 11.880332946777344,
      "learning_rate": 3.813125e-05,
      "loss": 0.5074,
      "step": 1900
    },
    {
      "epoch": 1.95,
      "grad_norm": 5.929384708404541,
      "learning_rate": 3.781875e-05,
      "loss": 0.5062,
      "step": 1950
    },
    {
      "epoch": 2.0,
      "grad_norm": 9.312037467956543,
      "learning_rate": 3.750625000000001e-05,
      "loss": 0.5392,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8725,
      "eval_f1_score": 0.8725,
      "eval_loss": 0.44224029779434204,
      "eval_runtime": 6.6752,
      "eval_samples_per_second": 299.618,
      "eval_steps_per_second": 18.726,
      "step": 2000
    },
    {
      "epoch": 2.05,
      "grad_norm": 5.317986011505127,
      "learning_rate": 3.719375e-05,
      "loss": 0.496,
      "step": 2050
    },
    {
      "epoch": 2.1,
      "grad_norm": 10.230167388916016,
      "learning_rate": 3.688125e-05,
      "loss": 0.4877,
      "step": 2100
    },
    {
      "epoch": 2.15,
      "grad_norm": 4.632346153259277,
      "learning_rate": 3.6568750000000005e-05,
      "loss": 0.415,
      "step": 2150
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.040151596069336,
      "learning_rate": 3.6256250000000004e-05,
      "loss": 0.4086,
      "step": 2200
    },
    {
      "epoch": 2.25,
      "grad_norm": 4.502320289611816,
      "learning_rate": 3.594375e-05,
      "loss": 0.4341,
      "step": 2250
    },
    {
      "epoch": 2.3,
      "grad_norm": 11.494647026062012,
      "learning_rate": 3.563125e-05,
      "loss": 0.4235,
      "step": 2300
    },
    {
      "epoch": 2.35,
      "grad_norm": 4.567110061645508,
      "learning_rate": 3.531875e-05,
      "loss": 0.4025,
      "step": 2350
    },
    {
      "epoch": 2.4,
      "grad_norm": 11.496413230895996,
      "learning_rate": 3.500625e-05,
      "loss": 0.3887,
      "step": 2400
    },
    {
      "epoch": 2.45,
      "grad_norm": 8.722079277038574,
      "learning_rate": 3.469375e-05,
      "loss": 0.3982,
      "step": 2450
    },
    {
      "epoch": 2.5,
      "grad_norm": 5.627297878265381,
      "learning_rate": 3.4381250000000006e-05,
      "loss": 0.4178,
      "step": 2500
    },
    {
      "epoch": 2.55,
      "grad_norm": 8.655062675476074,
      "learning_rate": 3.406875e-05,
      "loss": 0.3842,
      "step": 2550
    },
    {
      "epoch": 2.6,
      "grad_norm": 4.393942356109619,
      "learning_rate": 3.375625e-05,
      "loss": 0.3928,
      "step": 2600
    },
    {
      "epoch": 2.65,
      "grad_norm": 20.135757446289062,
      "learning_rate": 3.344375e-05,
      "loss": 0.3863,
      "step": 2650
    },
    {
      "epoch": 2.7,
      "grad_norm": 18.543176651000977,
      "learning_rate": 3.313125e-05,
      "loss": 0.4066,
      "step": 2700
    },
    {
      "epoch": 2.75,
      "grad_norm": 10.27491569519043,
      "learning_rate": 3.281875e-05,
      "loss": 0.3773,
      "step": 2750
    },
    {
      "epoch": 2.8,
      "grad_norm": 14.347335815429688,
      "learning_rate": 3.250625e-05,
      "loss": 0.3495,
      "step": 2800
    },
    {
      "epoch": 2.85,
      "grad_norm": 7.705931186676025,
      "learning_rate": 3.219375e-05,
      "loss": 0.4377,
      "step": 2850
    },
    {
      "epoch": 2.9,
      "grad_norm": 4.033046245574951,
      "learning_rate": 3.188125e-05,
      "loss": 0.3915,
      "step": 2900
    },
    {
      "epoch": 2.95,
      "grad_norm": 7.306375026702881,
      "learning_rate": 3.1568750000000005e-05,
      "loss": 0.365,
      "step": 2950
    },
    {
      "epoch": 3.0,
      "grad_norm": 7.0794548988342285,
      "learning_rate": 3.1256250000000004e-05,
      "loss": 0.3808,
      "step": 3000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.886,
      "eval_f1_score": 0.886,
      "eval_loss": 0.33036717772483826,
      "eval_runtime": 5.0964,
      "eval_samples_per_second": 392.433,
      "eval_steps_per_second": 24.527,
      "step": 3000
    },
    {
      "epoch": 3.05,
      "grad_norm": 14.543658256530762,
      "learning_rate": 3.0943749999999997e-05,
      "loss": 0.3417,
      "step": 3050
    },
    {
      "epoch": 3.1,
      "grad_norm": 11.949165344238281,
      "learning_rate": 3.063125e-05,
      "loss": 0.3168,
      "step": 3100
    },
    {
      "epoch": 3.15,
      "grad_norm": 6.641449928283691,
      "learning_rate": 3.0318750000000002e-05,
      "loss": 0.3003,
      "step": 3150
    },
    {
      "epoch": 3.2,
      "grad_norm": 10.999390602111816,
      "learning_rate": 3.000625e-05,
      "loss": 0.3698,
      "step": 3200
    },
    {
      "epoch": 3.25,
      "grad_norm": 1.4704095125198364,
      "learning_rate": 2.9693750000000003e-05,
      "loss": 0.3361,
      "step": 3250
    },
    {
      "epoch": 3.3,
      "grad_norm": 10.236943244934082,
      "learning_rate": 2.938125e-05,
      "loss": 0.2691,
      "step": 3300
    },
    {
      "epoch": 3.35,
      "grad_norm": 5.560693740844727,
      "learning_rate": 2.9068750000000002e-05,
      "loss": 0.3078,
      "step": 3350
    },
    {
      "epoch": 3.4,
      "grad_norm": 14.757484436035156,
      "learning_rate": 2.875625e-05,
      "loss": 0.3855,
      "step": 3400
    },
    {
      "epoch": 3.45,
      "grad_norm": 16.10614013671875,
      "learning_rate": 2.8443750000000004e-05,
      "loss": 0.3239,
      "step": 3450
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.0252630710601807,
      "learning_rate": 2.8131250000000003e-05,
      "loss": 0.349,
      "step": 3500
    },
    {
      "epoch": 3.55,
      "grad_norm": 9.784936904907227,
      "learning_rate": 2.781875e-05,
      "loss": 0.3367,
      "step": 3550
    },
    {
      "epoch": 3.6,
      "grad_norm": 8.372138023376465,
      "learning_rate": 2.750625e-05,
      "loss": 0.33,
      "step": 3600
    },
    {
      "epoch": 3.65,
      "grad_norm": 10.773324966430664,
      "learning_rate": 2.719375e-05,
      "loss": 0.3133,
      "step": 3650
    },
    {
      "epoch": 3.7,
      "grad_norm": 5.284621238708496,
      "learning_rate": 2.6881250000000003e-05,
      "loss": 0.342,
      "step": 3700
    },
    {
      "epoch": 3.75,
      "grad_norm": 5.472443580627441,
      "learning_rate": 2.6568750000000002e-05,
      "loss": 0.2807,
      "step": 3750
    },
    {
      "epoch": 3.8,
      "grad_norm": 23.868022918701172,
      "learning_rate": 2.6256249999999998e-05,
      "loss": 0.3581,
      "step": 3800
    },
    {
      "epoch": 3.85,
      "grad_norm": 3.6856627464294434,
      "learning_rate": 2.594375e-05,
      "loss": 0.3063,
      "step": 3850
    },
    {
      "epoch": 3.9,
      "grad_norm": 13.632187843322754,
      "learning_rate": 2.563125e-05,
      "loss": 0.3267,
      "step": 3900
    },
    {
      "epoch": 3.95,
      "grad_norm": 15.898911476135254,
      "learning_rate": 2.5318750000000002e-05,
      "loss": 0.2888,
      "step": 3950
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.2662134170532227,
      "learning_rate": 2.5006250000000005e-05,
      "loss": 0.336,
      "step": 4000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.893,
      "eval_f1_score": 0.893,
      "eval_loss": 0.2895370125770569,
      "eval_runtime": 13.289,
      "eval_samples_per_second": 150.5,
      "eval_steps_per_second": 9.406,
      "step": 4000
    },
    {
      "epoch": 4.05,
      "grad_norm": 10.865704536437988,
      "learning_rate": 2.469375e-05,
      "loss": 0.2725,
      "step": 4050
    },
    {
      "epoch": 4.1,
      "grad_norm": 6.307469844818115,
      "learning_rate": 2.438125e-05,
      "loss": 0.2696,
      "step": 4100
    },
    {
      "epoch": 4.15,
      "grad_norm": 6.469046115875244,
      "learning_rate": 2.4068750000000002e-05,
      "loss": 0.2217,
      "step": 4150
    },
    {
      "epoch": 4.2,
      "grad_norm": 18.193288803100586,
      "learning_rate": 2.375625e-05,
      "loss": 0.333,
      "step": 4200
    },
    {
      "epoch": 4.25,
      "grad_norm": 19.423824310302734,
      "learning_rate": 2.344375e-05,
      "loss": 0.2993,
      "step": 4250
    },
    {
      "epoch": 4.3,
      "grad_norm": 11.589695930480957,
      "learning_rate": 2.3131250000000003e-05,
      "loss": 0.2921,
      "step": 4300
    },
    {
      "epoch": 4.35,
      "grad_norm": 19.001848220825195,
      "learning_rate": 2.281875e-05,
      "loss": 0.3031,
      "step": 4350
    },
    {
      "epoch": 4.4,
      "grad_norm": 19.122581481933594,
      "learning_rate": 2.250625e-05,
      "loss": 0.2855,
      "step": 4400
    },
    {
      "epoch": 4.45,
      "grad_norm": 3.533737897872925,
      "learning_rate": 2.219375e-05,
      "loss": 0.308,
      "step": 4450
    },
    {
      "epoch": 4.5,
      "grad_norm": 6.164892673492432,
      "learning_rate": 2.188125e-05,
      "loss": 0.283,
      "step": 4500
    },
    {
      "epoch": 4.55,
      "grad_norm": 11.941121101379395,
      "learning_rate": 2.1568750000000002e-05,
      "loss": 0.2662,
      "step": 4550
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.5198090672492981,
      "learning_rate": 2.1256249999999998e-05,
      "loss": 0.2507,
      "step": 4600
    },
    {
      "epoch": 4.65,
      "grad_norm": 19.10838508605957,
      "learning_rate": 2.094375e-05,
      "loss": 0.2726,
      "step": 4650
    },
    {
      "epoch": 4.7,
      "grad_norm": 2.5288331508636475,
      "learning_rate": 2.0631250000000003e-05,
      "loss": 0.3023,
      "step": 4700
    },
    {
      "epoch": 4.75,
      "grad_norm": 23.907047271728516,
      "learning_rate": 2.031875e-05,
      "loss": 0.2935,
      "step": 4750
    },
    {
      "epoch": 4.8,
      "grad_norm": 19.26946258544922,
      "learning_rate": 2.0006250000000002e-05,
      "loss": 0.2711,
      "step": 4800
    },
    {
      "epoch": 4.85,
      "grad_norm": 10.575139045715332,
      "learning_rate": 1.969375e-05,
      "loss": 0.2768,
      "step": 4850
    },
    {
      "epoch": 4.9,
      "grad_norm": 7.652369499206543,
      "learning_rate": 1.938125e-05,
      "loss": 0.2948,
      "step": 4900
    },
    {
      "epoch": 4.95,
      "grad_norm": 26.24667739868164,
      "learning_rate": 1.9068750000000003e-05,
      "loss": 0.2727,
      "step": 4950
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.7988860607147217,
      "learning_rate": 1.8756250000000002e-05,
      "loss": 0.2869,
      "step": 5000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8995,
      "eval_f1_score": 0.8995,
      "eval_loss": 0.2787306606769562,
      "eval_runtime": 5.3408,
      "eval_samples_per_second": 374.477,
      "eval_steps_per_second": 23.405,
      "step": 5000
    },
    {
      "epoch": 5.05,
      "grad_norm": 15.707284927368164,
      "learning_rate": 1.844375e-05,
      "loss": 0.2574,
      "step": 5050
    },
    {
      "epoch": 5.1,
      "grad_norm": 20.119243621826172,
      "learning_rate": 1.813125e-05,
      "loss": 0.2435,
      "step": 5100
    },
    {
      "epoch": 5.15,
      "grad_norm": 17.49991226196289,
      "learning_rate": 1.781875e-05,
      "loss": 0.2639,
      "step": 5150
    },
    {
      "epoch": 5.2,
      "grad_norm": 27.738882064819336,
      "learning_rate": 1.7506250000000002e-05,
      "loss": 0.3005,
      "step": 5200
    },
    {
      "epoch": 5.25,
      "grad_norm": 7.114595890045166,
      "learning_rate": 1.719375e-05,
      "loss": 0.2617,
      "step": 5250
    },
    {
      "epoch": 5.3,
      "grad_norm": 1.8903331756591797,
      "learning_rate": 1.688125e-05,
      "loss": 0.2181,
      "step": 5300
    },
    {
      "epoch": 5.35,
      "grad_norm": 1.8864933252334595,
      "learning_rate": 1.656875e-05,
      "loss": 0.2041,
      "step": 5350
    },
    {
      "epoch": 5.4,
      "grad_norm": 4.442217826843262,
      "learning_rate": 1.6256250000000002e-05,
      "loss": 0.2404,
      "step": 5400
    },
    {
      "epoch": 5.45,
      "grad_norm": 4.464227676391602,
      "learning_rate": 1.594375e-05,
      "loss": 0.2797,
      "step": 5450
    },
    {
      "epoch": 5.5,
      "grad_norm": 9.307548522949219,
      "learning_rate": 1.563125e-05,
      "loss": 0.2443,
      "step": 5500
    },
    {
      "epoch": 5.55,
      "grad_norm": 1.768852710723877,
      "learning_rate": 1.531875e-05,
      "loss": 0.2519,
      "step": 5550
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.6975598931312561,
      "learning_rate": 1.5006249999999999e-05,
      "loss": 0.2694,
      "step": 5600
    },
    {
      "epoch": 5.65,
      "grad_norm": 11.260090827941895,
      "learning_rate": 1.4693750000000001e-05,
      "loss": 0.2256,
      "step": 5650
    },
    {
      "epoch": 5.7,
      "grad_norm": 2.201568365097046,
      "learning_rate": 1.4381250000000002e-05,
      "loss": 0.2261,
      "step": 5700
    },
    {
      "epoch": 5.75,
      "grad_norm": 10.513031005859375,
      "learning_rate": 1.406875e-05,
      "loss": 0.3111,
      "step": 5750
    },
    {
      "epoch": 5.8,
      "grad_norm": 26.481101989746094,
      "learning_rate": 1.375625e-05,
      "loss": 0.2557,
      "step": 5800
    },
    {
      "epoch": 5.85,
      "grad_norm": 12.882721900939941,
      "learning_rate": 1.344375e-05,
      "loss": 0.2255,
      "step": 5850
    },
    {
      "epoch": 5.9,
      "grad_norm": 7.809591770172119,
      "learning_rate": 1.313125e-05,
      "loss": 0.2257,
      "step": 5900
    },
    {
      "epoch": 5.95,
      "grad_norm": 10.848868370056152,
      "learning_rate": 1.2818750000000002e-05,
      "loss": 0.2586,
      "step": 5950
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.8735913038253784,
      "learning_rate": 1.250625e-05,
      "loss": 0.2311,
      "step": 6000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.906,
      "eval_f1_score": 0.906,
      "eval_loss": 0.262758731842041,
      "eval_runtime": 5.0385,
      "eval_samples_per_second": 396.94,
      "eval_steps_per_second": 24.809,
      "step": 6000
    },
    {
      "epoch": 6.05,
      "grad_norm": 7.322696208953857,
      "learning_rate": 1.2193750000000002e-05,
      "loss": 0.2448,
      "step": 6050
    },
    {
      "epoch": 6.1,
      "grad_norm": 12.292768478393555,
      "learning_rate": 1.188125e-05,
      "loss": 0.2383,
      "step": 6100
    },
    {
      "epoch": 6.15,
      "grad_norm": 15.094449043273926,
      "learning_rate": 1.156875e-05,
      "loss": 0.2571,
      "step": 6150
    },
    {
      "epoch": 6.2,
      "grad_norm": 15.15522575378418,
      "learning_rate": 1.1256250000000001e-05,
      "loss": 0.2268,
      "step": 6200
    },
    {
      "epoch": 6.25,
      "grad_norm": 11.083109855651855,
      "learning_rate": 1.094375e-05,
      "loss": 0.257,
      "step": 6250
    },
    {
      "epoch": 6.3,
      "grad_norm": 4.445398807525635,
      "learning_rate": 1.0631250000000001e-05,
      "loss": 0.2239,
      "step": 6300
    },
    {
      "epoch": 6.35,
      "grad_norm": 17.817806243896484,
      "learning_rate": 1.031875e-05,
      "loss": 0.2233,
      "step": 6350
    },
    {
      "epoch": 6.4,
      "grad_norm": 15.364806175231934,
      "learning_rate": 1.0006250000000001e-05,
      "loss": 0.2292,
      "step": 6400
    },
    {
      "epoch": 6.45,
      "grad_norm": 3.7595250606536865,
      "learning_rate": 9.69375e-06,
      "loss": 0.2519,
      "step": 6450
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.4019168615341187,
      "learning_rate": 9.38125e-06,
      "loss": 0.2411,
      "step": 6500
    },
    {
      "epoch": 6.55,
      "grad_norm": 11.05448055267334,
      "learning_rate": 9.06875e-06,
      "loss": 0.2438,
      "step": 6550
    },
    {
      "epoch": 6.6,
      "grad_norm": 5.042612075805664,
      "learning_rate": 8.756250000000001e-06,
      "loss": 0.1898,
      "step": 6600
    },
    {
      "epoch": 6.65,
      "grad_norm": 3.212435245513916,
      "learning_rate": 8.44375e-06,
      "loss": 0.2586,
      "step": 6650
    },
    {
      "epoch": 6.7,
      "grad_norm": 8.68130874633789,
      "learning_rate": 8.13125e-06,
      "loss": 0.2776,
      "step": 6700
    },
    {
      "epoch": 6.75,
      "grad_norm": 7.5598344802856445,
      "learning_rate": 7.81875e-06,
      "loss": 0.1927,
      "step": 6750
    },
    {
      "epoch": 6.8,
      "grad_norm": 19.455638885498047,
      "learning_rate": 7.506250000000001e-06,
      "loss": 0.271,
      "step": 6800
    },
    {
      "epoch": 6.85,
      "grad_norm": 0.6801464557647705,
      "learning_rate": 7.19375e-06,
      "loss": 0.2054,
      "step": 6850
    },
    {
      "epoch": 6.9,
      "grad_norm": 9.033126831054688,
      "learning_rate": 6.88125e-06,
      "loss": 0.2293,
      "step": 6900
    },
    {
      "epoch": 6.95,
      "grad_norm": 8.637481689453125,
      "learning_rate": 6.56875e-06,
      "loss": 0.2315,
      "step": 6950
    },
    {
      "epoch": 7.0,
      "grad_norm": 25.023876190185547,
      "learning_rate": 6.25625e-06,
      "loss": 0.2453,
      "step": 7000
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.905,
      "eval_f1_score": 0.905,
      "eval_loss": 0.25786682963371277,
      "eval_runtime": 5.1626,
      "eval_samples_per_second": 387.402,
      "eval_steps_per_second": 24.213,
      "step": 7000
    },
    {
      "epoch": 7.05,
      "grad_norm": 11.723291397094727,
      "learning_rate": 5.94375e-06,
      "loss": 0.2266,
      "step": 7050
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.187081217765808,
      "learning_rate": 5.6312500000000005e-06,
      "loss": 0.2342,
      "step": 7100
    },
    {
      "epoch": 7.15,
      "grad_norm": 0.5386338829994202,
      "learning_rate": 5.3187500000000005e-06,
      "loss": 0.1906,
      "step": 7150
    },
    {
      "epoch": 7.2,
      "grad_norm": 8.793124198913574,
      "learning_rate": 5.0062500000000006e-06,
      "loss": 0.2135,
      "step": 7200
    },
    {
      "epoch": 7.25,
      "grad_norm": 24.453989028930664,
      "learning_rate": 4.693750000000001e-06,
      "loss": 0.1904,
      "step": 7250
    },
    {
      "epoch": 7.3,
      "grad_norm": 15.157671928405762,
      "learning_rate": 4.38125e-06,
      "loss": 0.271,
      "step": 7300
    },
    {
      "epoch": 7.35,
      "grad_norm": 24.88811683654785,
      "learning_rate": 4.068750000000001e-06,
      "loss": 0.2307,
      "step": 7350
    },
    {
      "epoch": 7.4,
      "grad_norm": 2.351710319519043,
      "learning_rate": 3.7562500000000002e-06,
      "loss": 0.2286,
      "step": 7400
    },
    {
      "epoch": 7.45,
      "grad_norm": 13.178778648376465,
      "learning_rate": 3.4437500000000003e-06,
      "loss": 0.2034,
      "step": 7450
    },
    {
      "epoch": 7.5,
      "grad_norm": 11.301623344421387,
      "learning_rate": 3.1312500000000003e-06,
      "loss": 0.2152,
      "step": 7500
    },
    {
      "epoch": 7.55,
      "grad_norm": 9.33810806274414,
      "learning_rate": 2.8187500000000003e-06,
      "loss": 0.2191,
      "step": 7550
    },
    {
      "epoch": 7.6,
      "grad_norm": 5.114279747009277,
      "learning_rate": 2.5062500000000004e-06,
      "loss": 0.2391,
      "step": 7600
    },
    {
      "epoch": 7.65,
      "grad_norm": 10.617246627807617,
      "learning_rate": 2.19375e-06,
      "loss": 0.2035,
      "step": 7650
    },
    {
      "epoch": 7.7,
      "grad_norm": 2.548442840576172,
      "learning_rate": 1.88125e-06,
      "loss": 0.2069,
      "step": 7700
    },
    {
      "epoch": 7.75,
      "grad_norm": 12.670727729797363,
      "learning_rate": 1.56875e-06,
      "loss": 0.2971,
      "step": 7750
    },
    {
      "epoch": 7.8,
      "grad_norm": 4.487941265106201,
      "learning_rate": 1.25625e-06,
      "loss": 0.256,
      "step": 7800
    },
    {
      "epoch": 7.85,
      "grad_norm": 18.070945739746094,
      "learning_rate": 9.4375e-07,
      "loss": 0.208,
      "step": 7850
    },
    {
      "epoch": 7.9,
      "grad_norm": 11.563258171081543,
      "learning_rate": 6.312500000000001e-07,
      "loss": 0.2501,
      "step": 7900
    },
    {
      "epoch": 7.95,
      "grad_norm": 16.48257064819336,
      "learning_rate": 3.1875e-07,
      "loss": 0.2226,
      "step": 7950
    },
    {
      "epoch": 8.0,
      "grad_norm": 3.6392247676849365,
      "learning_rate": 6.2500000000000005e-09,
      "loss": 0.239,
      "step": 8000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9075,
      "eval_f1_score": 0.9075,
      "eval_loss": 0.2573521137237549,
      "eval_runtime": 9.667,
      "eval_samples_per_second": 206.889,
      "eval_steps_per_second": 12.931,
      "step": 8000
    }
  ],
  "logging_steps": 50,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 40706310144000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
