{
  "best_metric": 0.8603098957363916,
  "best_model_checkpoint": "./results/bert_uncased_L-2_H-128_A-2-finetuned-emotion\\checkpoint-21336",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 21336,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018747656542932135,
      "grad_norm": 3.3703901767730713,
      "learning_rate": 4.9882827146606675e-05,
      "loss": 1.7432,
      "step": 50
    },
    {
      "epoch": 0.03749531308586427,
      "grad_norm": 4.074295520782471,
      "learning_rate": 4.976565429321335e-05,
      "loss": 1.6664,
      "step": 100
    },
    {
      "epoch": 0.0562429696287964,
      "grad_norm": 3.014028310775757,
      "learning_rate": 4.964848143982003e-05,
      "loss": 1.6304,
      "step": 150
    },
    {
      "epoch": 0.07499062617172854,
      "grad_norm": 4.138988018035889,
      "learning_rate": 4.95313085864267e-05,
      "loss": 1.5825,
      "step": 200
    },
    {
      "epoch": 0.09373828271466067,
      "grad_norm": 2.96952223777771,
      "learning_rate": 4.941413573303337e-05,
      "loss": 1.5616,
      "step": 250
    },
    {
      "epoch": 0.1124859392575928,
      "grad_norm": 3.920757293701172,
      "learning_rate": 4.9296962879640045e-05,
      "loss": 1.5775,
      "step": 300
    },
    {
      "epoch": 0.13123359580052493,
      "grad_norm": 2.679279088973999,
      "learning_rate": 4.917979002624672e-05,
      "loss": 1.5912,
      "step": 350
    },
    {
      "epoch": 0.14998125234345708,
      "grad_norm": 4.29516077041626,
      "learning_rate": 4.90626171728534e-05,
      "loss": 1.5606,
      "step": 400
    },
    {
      "epoch": 0.1687289088863892,
      "grad_norm": 4.346121788024902,
      "learning_rate": 4.894544431946007e-05,
      "loss": 1.5378,
      "step": 450
    },
    {
      "epoch": 0.18747656542932134,
      "grad_norm": 5.231137275695801,
      "learning_rate": 4.882827146606674e-05,
      "loss": 1.4949,
      "step": 500
    },
    {
      "epoch": 0.20622422197225346,
      "grad_norm": 7.083184242248535,
      "learning_rate": 4.8711098612673415e-05,
      "loss": 1.4621,
      "step": 550
    },
    {
      "epoch": 0.2249718785151856,
      "grad_norm": 3.336244583129883,
      "learning_rate": 4.859392575928009e-05,
      "loss": 1.4041,
      "step": 600
    },
    {
      "epoch": 0.24371953505811775,
      "grad_norm": 8.446730613708496,
      "learning_rate": 4.847675290588677e-05,
      "loss": 1.3754,
      "step": 650
    },
    {
      "epoch": 0.26246719160104987,
      "grad_norm": 8.086044311523438,
      "learning_rate": 4.835958005249344e-05,
      "loss": 1.3232,
      "step": 700
    },
    {
      "epoch": 0.281214848143982,
      "grad_norm": 10.992621421813965,
      "learning_rate": 4.824240719910011e-05,
      "loss": 1.3287,
      "step": 750
    },
    {
      "epoch": 0.29996250468691416,
      "grad_norm": 3.427231788635254,
      "learning_rate": 4.8125234345706785e-05,
      "loss": 1.2274,
      "step": 800
    },
    {
      "epoch": 0.31871016122984624,
      "grad_norm": 4.126352310180664,
      "learning_rate": 4.8008061492313464e-05,
      "loss": 1.276,
      "step": 850
    },
    {
      "epoch": 0.3374578177727784,
      "grad_norm": 11.791624069213867,
      "learning_rate": 4.789088863892014e-05,
      "loss": 1.212,
      "step": 900
    },
    {
      "epoch": 0.35620547431571054,
      "grad_norm": 5.285716533660889,
      "learning_rate": 4.777371578552681e-05,
      "loss": 1.201,
      "step": 950
    },
    {
      "epoch": 0.3749531308586427,
      "grad_norm": 8.683796882629395,
      "learning_rate": 4.765654293213349e-05,
      "loss": 1.1176,
      "step": 1000
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 14.964680671691895,
      "learning_rate": 4.753937007874016e-05,
      "loss": 1.1042,
      "step": 1050
    },
    {
      "epoch": 0.4124484439445069,
      "grad_norm": 7.38566255569458,
      "learning_rate": 4.7422197225346834e-05,
      "loss": 1.0777,
      "step": 1100
    },
    {
      "epoch": 0.43119610048743906,
      "grad_norm": 5.642103672027588,
      "learning_rate": 4.730502437195351e-05,
      "loss": 0.9626,
      "step": 1150
    },
    {
      "epoch": 0.4499437570303712,
      "grad_norm": 3.0814054012298584,
      "learning_rate": 4.7187851518560186e-05,
      "loss": 0.9576,
      "step": 1200
    },
    {
      "epoch": 0.46869141357330335,
      "grad_norm": 6.851626396179199,
      "learning_rate": 4.707067866516686e-05,
      "loss": 1.0344,
      "step": 1250
    },
    {
      "epoch": 0.4874390701162355,
      "grad_norm": 6.590702056884766,
      "learning_rate": 4.695350581177353e-05,
      "loss": 0.9842,
      "step": 1300
    },
    {
      "epoch": 0.5061867266591676,
      "grad_norm": 3.6774404048919678,
      "learning_rate": 4.6836332958380204e-05,
      "loss": 0.9406,
      "step": 1350
    },
    {
      "epoch": 0.5249343832020997,
      "grad_norm": 6.2109293937683105,
      "learning_rate": 4.672150356205475e-05,
      "loss": 0.9149,
      "step": 1400
    },
    {
      "epoch": 0.5436820397450318,
      "grad_norm": 7.8621697425842285,
      "learning_rate": 4.660433070866142e-05,
      "loss": 0.8942,
      "step": 1450
    },
    {
      "epoch": 0.562429696287964,
      "grad_norm": 3.337404727935791,
      "learning_rate": 4.648715785526809e-05,
      "loss": 0.9053,
      "step": 1500
    },
    {
      "epoch": 0.5811773528308961,
      "grad_norm": 8.368950843811035,
      "learning_rate": 4.6369985001874766e-05,
      "loss": 0.8248,
      "step": 1550
    },
    {
      "epoch": 0.5999250093738283,
      "grad_norm": 14.927717208862305,
      "learning_rate": 4.6252812148481445e-05,
      "loss": 0.7886,
      "step": 1600
    },
    {
      "epoch": 0.6186726659167604,
      "grad_norm": 3.837955951690674,
      "learning_rate": 4.613563929508812e-05,
      "loss": 0.8575,
      "step": 1650
    },
    {
      "epoch": 0.6374203224596925,
      "grad_norm": 22.43032455444336,
      "learning_rate": 4.601846644169479e-05,
      "loss": 0.8371,
      "step": 1700
    },
    {
      "epoch": 0.6561679790026247,
      "grad_norm": 7.360870838165283,
      "learning_rate": 4.590129358830146e-05,
      "loss": 0.8757,
      "step": 1750
    },
    {
      "epoch": 0.6749156355455568,
      "grad_norm": 21.996992111206055,
      "learning_rate": 4.5784120734908136e-05,
      "loss": 0.7632,
      "step": 1800
    },
    {
      "epoch": 0.693663292088489,
      "grad_norm": 8.408568382263184,
      "learning_rate": 4.5666947881514815e-05,
      "loss": 0.7458,
      "step": 1850
    },
    {
      "epoch": 0.7124109486314211,
      "grad_norm": 7.000205993652344,
      "learning_rate": 4.554977502812149e-05,
      "loss": 0.7276,
      "step": 1900
    },
    {
      "epoch": 0.7311586051743532,
      "grad_norm": 7.731533527374268,
      "learning_rate": 4.543260217472816e-05,
      "loss": 0.7699,
      "step": 1950
    },
    {
      "epoch": 0.7499062617172854,
      "grad_norm": 6.1941094398498535,
      "learning_rate": 4.531542932133483e-05,
      "loss": 0.6809,
      "step": 2000
    },
    {
      "epoch": 0.7686539182602175,
      "grad_norm": 23.7222843170166,
      "learning_rate": 4.5198256467941505e-05,
      "loss": 0.7276,
      "step": 2050
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 24.657033920288086,
      "learning_rate": 4.5081083614548185e-05,
      "loss": 0.7244,
      "step": 2100
    },
    {
      "epoch": 0.8061492313460817,
      "grad_norm": 9.412190437316895,
      "learning_rate": 4.496391076115486e-05,
      "loss": 0.716,
      "step": 2150
    },
    {
      "epoch": 0.8248968878890138,
      "grad_norm": 5.769283771514893,
      "learning_rate": 4.484673790776153e-05,
      "loss": 0.7005,
      "step": 2200
    },
    {
      "epoch": 0.843644544431946,
      "grad_norm": 27.638744354248047,
      "learning_rate": 4.47295650543682e-05,
      "loss": 0.5414,
      "step": 2250
    },
    {
      "epoch": 0.8623922009748781,
      "grad_norm": 3.076570749282837,
      "learning_rate": 4.4612392200974875e-05,
      "loss": 0.6914,
      "step": 2300
    },
    {
      "epoch": 0.8811398575178103,
      "grad_norm": 3.6257779598236084,
      "learning_rate": 4.4495219347581555e-05,
      "loss": 0.6185,
      "step": 2350
    },
    {
      "epoch": 0.8998875140607424,
      "grad_norm": 8.702842712402344,
      "learning_rate": 4.437804649418823e-05,
      "loss": 0.6273,
      "step": 2400
    },
    {
      "epoch": 0.9186351706036745,
      "grad_norm": 25.15342903137207,
      "learning_rate": 4.42608736407949e-05,
      "loss": 0.6951,
      "step": 2450
    },
    {
      "epoch": 0.9373828271466067,
      "grad_norm": 15.161450386047363,
      "learning_rate": 4.414370078740158e-05,
      "loss": 0.6197,
      "step": 2500
    },
    {
      "epoch": 0.9561304836895388,
      "grad_norm": 21.956022262573242,
      "learning_rate": 4.402652793400825e-05,
      "loss": 0.5613,
      "step": 2550
    },
    {
      "epoch": 0.974878140232471,
      "grad_norm": 9.717877388000488,
      "learning_rate": 4.3909355080614925e-05,
      "loss": 0.5463,
      "step": 2600
    },
    {
      "epoch": 0.9936257967754031,
      "grad_norm": 31.34848976135254,
      "learning_rate": 4.3792182227221604e-05,
      "loss": 0.5826,
      "step": 2650
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.857,
      "eval_f1_score": 0.7938307060088102,
      "eval_loss": 0.48183074593544006,
      "eval_runtime": 3.548,
      "eval_samples_per_second": 563.691,
      "eval_steps_per_second": 94.136,
      "step": 2667
    },
    {
      "epoch": 1.0123734533183353,
      "grad_norm": 1.7727911472320557,
      "learning_rate": 4.3675009373828277e-05,
      "loss": 0.512,
      "step": 2700
    },
    {
      "epoch": 1.0311211098612674,
      "grad_norm": 29.05089569091797,
      "learning_rate": 4.355783652043495e-05,
      "loss": 0.4417,
      "step": 2750
    },
    {
      "epoch": 1.0498687664041995,
      "grad_norm": 22.15199089050293,
      "learning_rate": 4.344066366704162e-05,
      "loss": 0.4788,
      "step": 2800
    },
    {
      "epoch": 1.0686164229471316,
      "grad_norm": 1.7665444612503052,
      "learning_rate": 4.33234908136483e-05,
      "loss": 0.4943,
      "step": 2850
    },
    {
      "epoch": 1.0873640794900636,
      "grad_norm": 24.350955963134766,
      "learning_rate": 4.3206317960254974e-05,
      "loss": 0.4558,
      "step": 2900
    },
    {
      "epoch": 1.106111736032996,
      "grad_norm": 11.354570388793945,
      "learning_rate": 4.3089145106861646e-05,
      "loss": 0.4671,
      "step": 2950
    },
    {
      "epoch": 1.124859392575928,
      "grad_norm": 8.881242752075195,
      "learning_rate": 4.297197225346832e-05,
      "loss": 0.5373,
      "step": 3000
    },
    {
      "epoch": 1.1436070491188601,
      "grad_norm": 5.5821146965026855,
      "learning_rate": 4.285479940007499e-05,
      "loss": 0.4628,
      "step": 3050
    },
    {
      "epoch": 1.1623547056617922,
      "grad_norm": 9.791812896728516,
      "learning_rate": 4.2739970003749536e-05,
      "loss": 0.4471,
      "step": 3100
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 31.01396369934082,
      "learning_rate": 4.262279715035621e-05,
      "loss": 0.4511,
      "step": 3150
    },
    {
      "epoch": 1.1998500187476566,
      "grad_norm": 12.756505012512207,
      "learning_rate": 4.250562429696288e-05,
      "loss": 0.513,
      "step": 3200
    },
    {
      "epoch": 1.2185976752905887,
      "grad_norm": 4.434633255004883,
      "learning_rate": 4.2388451443569554e-05,
      "loss": 0.4734,
      "step": 3250
    },
    {
      "epoch": 1.2373453318335208,
      "grad_norm": 16.090343475341797,
      "learning_rate": 4.2271278590176226e-05,
      "loss": 0.5371,
      "step": 3300
    },
    {
      "epoch": 1.256092988376453,
      "grad_norm": 10.090015411376953,
      "learning_rate": 4.2154105736782906e-05,
      "loss": 0.4434,
      "step": 3350
    },
    {
      "epoch": 1.2748406449193852,
      "grad_norm": 6.011059284210205,
      "learning_rate": 4.203693288338958e-05,
      "loss": 0.4236,
      "step": 3400
    },
    {
      "epoch": 1.2935883014623173,
      "grad_norm": 1.1397889852523804,
      "learning_rate": 4.191976002999625e-05,
      "loss": 0.3819,
      "step": 3450
    },
    {
      "epoch": 1.3123359580052494,
      "grad_norm": 25.629350662231445,
      "learning_rate": 4.1802587176602923e-05,
      "loss": 0.4443,
      "step": 3500
    },
    {
      "epoch": 1.3310836145481815,
      "grad_norm": 9.463972091674805,
      "learning_rate": 4.1685414323209596e-05,
      "loss": 0.4735,
      "step": 3550
    },
    {
      "epoch": 1.3498312710911136,
      "grad_norm": 11.72034740447998,
      "learning_rate": 4.1568241469816275e-05,
      "loss": 0.4362,
      "step": 3600
    },
    {
      "epoch": 1.3685789276340459,
      "grad_norm": 0.9750081896781921,
      "learning_rate": 4.145106861642295e-05,
      "loss": 0.4715,
      "step": 3650
    },
    {
      "epoch": 1.3873265841769777,
      "grad_norm": 34.0005989074707,
      "learning_rate": 4.133389576302962e-05,
      "loss": 0.3618,
      "step": 3700
    },
    {
      "epoch": 1.40607424071991,
      "grad_norm": 21.3510799407959,
      "learning_rate": 4.121672290963629e-05,
      "loss": 0.4257,
      "step": 3750
    },
    {
      "epoch": 1.4248218972628421,
      "grad_norm": 12.675877571105957,
      "learning_rate": 4.1099550056242966e-05,
      "loss": 0.5128,
      "step": 3800
    },
    {
      "epoch": 1.4435695538057742,
      "grad_norm": 1.0521631240844727,
      "learning_rate": 4.0982377202849645e-05,
      "loss": 0.4984,
      "step": 3850
    },
    {
      "epoch": 1.4623172103487065,
      "grad_norm": 6.540634632110596,
      "learning_rate": 4.086520434945632e-05,
      "loss": 0.4529,
      "step": 3900
    },
    {
      "epoch": 1.4810648668916384,
      "grad_norm": 9.396997451782227,
      "learning_rate": 4.074803149606299e-05,
      "loss": 0.4976,
      "step": 3950
    },
    {
      "epoch": 1.4998125234345707,
      "grad_norm": 0.36234745383262634,
      "learning_rate": 4.063085864266967e-05,
      "loss": 0.3948,
      "step": 4000
    },
    {
      "epoch": 1.5185601799775028,
      "grad_norm": 10.632527351379395,
      "learning_rate": 4.051368578927634e-05,
      "loss": 0.466,
      "step": 4050
    },
    {
      "epoch": 1.537307836520435,
      "grad_norm": 7.531885147094727,
      "learning_rate": 4.039651293588302e-05,
      "loss": 0.4066,
      "step": 4100
    },
    {
      "epoch": 1.5560554930633672,
      "grad_norm": 16.271806716918945,
      "learning_rate": 4.0279340082489695e-05,
      "loss": 0.4068,
      "step": 4150
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 15.79955768585205,
      "learning_rate": 4.016216722909637e-05,
      "loss": 0.3867,
      "step": 4200
    },
    {
      "epoch": 1.5935508061492314,
      "grad_norm": 1.9885073900222778,
      "learning_rate": 4.004499437570304e-05,
      "loss": 0.3956,
      "step": 4250
    },
    {
      "epoch": 1.6122984626921635,
      "grad_norm": 18.191879272460938,
      "learning_rate": 3.992782152230971e-05,
      "loss": 0.4284,
      "step": 4300
    },
    {
      "epoch": 1.6310461192350956,
      "grad_norm": 0.448259562253952,
      "learning_rate": 3.981064866891639e-05,
      "loss": 0.448,
      "step": 4350
    },
    {
      "epoch": 1.6497937757780279,
      "grad_norm": 1.8390415906906128,
      "learning_rate": 3.9693475815523064e-05,
      "loss": 0.3932,
      "step": 4400
    },
    {
      "epoch": 1.6685414323209597,
      "grad_norm": 30.077539443969727,
      "learning_rate": 3.957630296212974e-05,
      "loss": 0.4533,
      "step": 4450
    },
    {
      "epoch": 1.687289088863892,
      "grad_norm": 30.513572692871094,
      "learning_rate": 3.945913010873641e-05,
      "loss": 0.4861,
      "step": 4500
    },
    {
      "epoch": 1.7060367454068242,
      "grad_norm": 35.42616653442383,
      "learning_rate": 3.934195725534308e-05,
      "loss": 0.4199,
      "step": 4550
    },
    {
      "epoch": 1.7247844019497562,
      "grad_norm": 44.705169677734375,
      "learning_rate": 3.922478440194976e-05,
      "loss": 0.3975,
      "step": 4600
    },
    {
      "epoch": 1.7435320584926886,
      "grad_norm": 37.6566276550293,
      "learning_rate": 3.9107611548556434e-05,
      "loss": 0.3902,
      "step": 4650
    },
    {
      "epoch": 1.7622797150356204,
      "grad_norm": 0.5007606744766235,
      "learning_rate": 3.899043869516311e-05,
      "loss": 0.3866,
      "step": 4700
    },
    {
      "epoch": 1.7810273715785527,
      "grad_norm": 15.566843032836914,
      "learning_rate": 3.887326584176978e-05,
      "loss": 0.3906,
      "step": 4750
    },
    {
      "epoch": 1.7997750281214848,
      "grad_norm": 6.9442458152771,
      "learning_rate": 3.875609298837645e-05,
      "loss": 0.4199,
      "step": 4800
    },
    {
      "epoch": 1.818522684664417,
      "grad_norm": 5.192269802093506,
      "learning_rate": 3.863892013498313e-05,
      "loss": 0.4268,
      "step": 4850
    },
    {
      "epoch": 1.8372703412073492,
      "grad_norm": 5.29115629196167,
      "learning_rate": 3.8521747281589804e-05,
      "loss": 0.5011,
      "step": 4900
    },
    {
      "epoch": 1.856017997750281,
      "grad_norm": 3.559603691101074,
      "learning_rate": 3.840457442819648e-05,
      "loss": 0.469,
      "step": 4950
    },
    {
      "epoch": 1.8747656542932134,
      "grad_norm": 0.6562824249267578,
      "learning_rate": 3.828740157480315e-05,
      "loss": 0.3382,
      "step": 5000
    },
    {
      "epoch": 1.8935133108361455,
      "grad_norm": 23.40679931640625,
      "learning_rate": 3.817022872140982e-05,
      "loss": 0.3897,
      "step": 5050
    },
    {
      "epoch": 1.9122609673790776,
      "grad_norm": 23.0946102142334,
      "learning_rate": 3.80530558680165e-05,
      "loss": 0.3322,
      "step": 5100
    },
    {
      "epoch": 1.93100862392201,
      "grad_norm": 16.624399185180664,
      "learning_rate": 3.7935883014623174e-05,
      "loss": 0.3554,
      "step": 5150
    },
    {
      "epoch": 1.9497562804649418,
      "grad_norm": 1.1785470247268677,
      "learning_rate": 3.782105361829771e-05,
      "loss": 0.343,
      "step": 5200
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 29.504037857055664,
      "learning_rate": 3.7703880764904384e-05,
      "loss": 0.3258,
      "step": 5250
    },
    {
      "epoch": 1.9872515935508062,
      "grad_norm": 7.874496936798096,
      "learning_rate": 3.758670791151106e-05,
      "loss": 0.3889,
      "step": 5300
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.885,
      "eval_f1_score": 0.8362404521033701,
      "eval_loss": 0.37189510464668274,
      "eval_runtime": 3.087,
      "eval_samples_per_second": 647.884,
      "eval_steps_per_second": 108.197,
      "step": 5334
    },
    {
      "epoch": 2.0059992500937383,
      "grad_norm": 3.0402944087982178,
      "learning_rate": 3.7469535058117736e-05,
      "loss": 0.3755,
      "step": 5350
    },
    {
      "epoch": 2.0247469066366706,
      "grad_norm": 2.216904640197754,
      "learning_rate": 3.735236220472441e-05,
      "loss": 0.3708,
      "step": 5400
    },
    {
      "epoch": 2.0434945631796024,
      "grad_norm": 25.014373779296875,
      "learning_rate": 3.723518935133108e-05,
      "loss": 0.4069,
      "step": 5450
    },
    {
      "epoch": 2.0622422197225347,
      "grad_norm": 12.488388061523438,
      "learning_rate": 3.7120359955005625e-05,
      "loss": 0.3453,
      "step": 5500
    },
    {
      "epoch": 2.0809898762654666,
      "grad_norm": 36.71332550048828,
      "learning_rate": 3.7003187101612305e-05,
      "loss": 0.3675,
      "step": 5550
    },
    {
      "epoch": 2.099737532808399,
      "grad_norm": 19.496061325073242,
      "learning_rate": 3.688601424821898e-05,
      "loss": 0.2495,
      "step": 5600
    },
    {
      "epoch": 2.1184851893513312,
      "grad_norm": 0.1457463502883911,
      "learning_rate": 3.676884139482565e-05,
      "loss": 0.4057,
      "step": 5650
    },
    {
      "epoch": 2.137232845894263,
      "grad_norm": 2.3326728343963623,
      "learning_rate": 3.665166854143232e-05,
      "loss": 0.3022,
      "step": 5700
    },
    {
      "epoch": 2.1559805024371954,
      "grad_norm": 1.1795347929000854,
      "learning_rate": 3.6534495688038995e-05,
      "loss": 0.3583,
      "step": 5750
    },
    {
      "epoch": 2.1747281589801273,
      "grad_norm": 11.633525848388672,
      "learning_rate": 3.6417322834645674e-05,
      "loss": 0.3204,
      "step": 5800
    },
    {
      "epoch": 2.1934758155230596,
      "grad_norm": 5.017077445983887,
      "learning_rate": 3.630014998125235e-05,
      "loss": 0.2173,
      "step": 5850
    },
    {
      "epoch": 2.212223472065992,
      "grad_norm": 0.25816425681114197,
      "learning_rate": 3.618297712785902e-05,
      "loss": 0.3602,
      "step": 5900
    },
    {
      "epoch": 2.2309711286089238,
      "grad_norm": 18.231760025024414,
      "learning_rate": 3.606580427446569e-05,
      "loss": 0.3702,
      "step": 5950
    },
    {
      "epoch": 2.249718785151856,
      "grad_norm": 0.7382540702819824,
      "learning_rate": 3.5948631421072365e-05,
      "loss": 0.3123,
      "step": 6000
    },
    {
      "epoch": 2.2684664416947884,
      "grad_norm": 0.11724179238080978,
      "learning_rate": 3.5831458567679044e-05,
      "loss": 0.3205,
      "step": 6050
    },
    {
      "epoch": 2.2872140982377203,
      "grad_norm": 22.61442756652832,
      "learning_rate": 3.571428571428572e-05,
      "loss": 0.4572,
      "step": 6100
    },
    {
      "epoch": 2.3059617547806526,
      "grad_norm": 19.916702270507812,
      "learning_rate": 3.559711286089239e-05,
      "loss": 0.282,
      "step": 6150
    },
    {
      "epoch": 2.3247094113235844,
      "grad_norm": 19.092269897460938,
      "learning_rate": 3.547994000749906e-05,
      "loss": 0.3245,
      "step": 6200
    },
    {
      "epoch": 2.3434570678665168,
      "grad_norm": 7.541750431060791,
      "learning_rate": 3.5362767154105735e-05,
      "loss": 0.427,
      "step": 6250
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 0.14030124247074127,
      "learning_rate": 3.5245594300712414e-05,
      "loss": 0.2646,
      "step": 6300
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 21.548187255859375,
      "learning_rate": 3.512842144731909e-05,
      "loss": 0.3116,
      "step": 6350
    },
    {
      "epoch": 2.3997000374953132,
      "grad_norm": 17.5703125,
      "learning_rate": 3.501124859392576e-05,
      "loss": 0.3034,
      "step": 6400
    },
    {
      "epoch": 2.418447694038245,
      "grad_norm": 22.970611572265625,
      "learning_rate": 3.489407574053243e-05,
      "loss": 0.3822,
      "step": 6450
    },
    {
      "epoch": 2.4371953505811774,
      "grad_norm": 26.31245994567871,
      "learning_rate": 3.4776902887139105e-05,
      "loss": 0.4016,
      "step": 6500
    },
    {
      "epoch": 2.4559430071241097,
      "grad_norm": 15.816781044006348,
      "learning_rate": 3.4659730033745784e-05,
      "loss": 0.3265,
      "step": 6550
    },
    {
      "epoch": 2.4746906636670416,
      "grad_norm": 33.76632308959961,
      "learning_rate": 3.454255718035246e-05,
      "loss": 0.3587,
      "step": 6600
    },
    {
      "epoch": 2.493438320209974,
      "grad_norm": 48.570011138916016,
      "learning_rate": 3.442538432695913e-05,
      "loss": 0.358,
      "step": 6650
    },
    {
      "epoch": 2.512185976752906,
      "grad_norm": 0.3716149628162384,
      "learning_rate": 3.43082114735658e-05,
      "loss": 0.3222,
      "step": 6700
    },
    {
      "epoch": 2.530933633295838,
      "grad_norm": 0.10872228443622589,
      "learning_rate": 3.4191038620172475e-05,
      "loss": 0.4036,
      "step": 6750
    },
    {
      "epoch": 2.5496812898387704,
      "grad_norm": 1.4948973655700684,
      "learning_rate": 3.4073865766779154e-05,
      "loss": 0.2833,
      "step": 6800
    },
    {
      "epoch": 2.5684289463817023,
      "grad_norm": 16.804704666137695,
      "learning_rate": 3.3956692913385827e-05,
      "loss": 0.3685,
      "step": 6850
    },
    {
      "epoch": 2.5871766029246346,
      "grad_norm": 26.461088180541992,
      "learning_rate": 3.38395200599925e-05,
      "loss": 0.2636,
      "step": 6900
    },
    {
      "epoch": 2.6059242594675665,
      "grad_norm": 9.737238883972168,
      "learning_rate": 3.372234720659918e-05,
      "loss": 0.3903,
      "step": 6950
    },
    {
      "epoch": 2.6246719160104988,
      "grad_norm": 14.7113618850708,
      "learning_rate": 3.360517435320585e-05,
      "loss": 0.3289,
      "step": 7000
    },
    {
      "epoch": 2.643419572553431,
      "grad_norm": 3.2810592651367188,
      "learning_rate": 3.3488001499812524e-05,
      "loss": 0.3029,
      "step": 7050
    },
    {
      "epoch": 2.662167229096363,
      "grad_norm": 40.20772933959961,
      "learning_rate": 3.33708286464192e-05,
      "loss": 0.384,
      "step": 7100
    },
    {
      "epoch": 2.6809148856392953,
      "grad_norm": 3.784698247909546,
      "learning_rate": 3.3253655793025876e-05,
      "loss": 0.3129,
      "step": 7150
    },
    {
      "epoch": 2.699662542182227,
      "grad_norm": 19.79250717163086,
      "learning_rate": 3.313648293963255e-05,
      "loss": 0.4281,
      "step": 7200
    },
    {
      "epoch": 2.7184101987251594,
      "grad_norm": 23.375444412231445,
      "learning_rate": 3.301931008623922e-05,
      "loss": 0.3549,
      "step": 7250
    },
    {
      "epoch": 2.7371578552680917,
      "grad_norm": 32.120140075683594,
      "learning_rate": 3.29021372328459e-05,
      "loss": 0.3738,
      "step": 7300
    },
    {
      "epoch": 2.7559055118110236,
      "grad_norm": 0.17571142315864563,
      "learning_rate": 3.278496437945257e-05,
      "loss": 0.2696,
      "step": 7350
    },
    {
      "epoch": 2.7746531683539555,
      "grad_norm": 0.043127141892910004,
      "learning_rate": 3.2667791526059246e-05,
      "loss": 0.3142,
      "step": 7400
    },
    {
      "epoch": 2.793400824896888,
      "grad_norm": 45.67716598510742,
      "learning_rate": 3.255061867266592e-05,
      "loss": 0.4006,
      "step": 7450
    },
    {
      "epoch": 2.81214848143982,
      "grad_norm": 0.07225114852190018,
      "learning_rate": 3.243344581927259e-05,
      "loss": 0.3961,
      "step": 7500
    },
    {
      "epoch": 2.8308961379827524,
      "grad_norm": 15.429363250732422,
      "learning_rate": 3.2318616422947135e-05,
      "loss": 0.4553,
      "step": 7550
    },
    {
      "epoch": 2.8496437945256843,
      "grad_norm": 0.40221381187438965,
      "learning_rate": 3.220144356955381e-05,
      "loss": 0.453,
      "step": 7600
    },
    {
      "epoch": 2.868391451068616,
      "grad_norm": 30.360063552856445,
      "learning_rate": 3.208427071616048e-05,
      "loss": 0.3061,
      "step": 7650
    },
    {
      "epoch": 2.8871391076115485,
      "grad_norm": 14.270780563354492,
      "learning_rate": 3.196709786276715e-05,
      "loss": 0.3167,
      "step": 7700
    },
    {
      "epoch": 2.9058867641544808,
      "grad_norm": 31.58386993408203,
      "learning_rate": 3.184992500937383e-05,
      "loss": 0.4181,
      "step": 7750
    },
    {
      "epoch": 2.924634420697413,
      "grad_norm": 0.3634493350982666,
      "learning_rate": 3.1732752155980505e-05,
      "loss": 0.2247,
      "step": 7800
    },
    {
      "epoch": 2.943382077240345,
      "grad_norm": 21.09218406677246,
      "learning_rate": 3.161557930258718e-05,
      "loss": 0.3756,
      "step": 7850
    },
    {
      "epoch": 2.962129733783277,
      "grad_norm": 1.0465525388717651,
      "learning_rate": 3.149840644919385e-05,
      "loss": 0.3546,
      "step": 7900
    },
    {
      "epoch": 2.980877390326209,
      "grad_norm": 33.802433013916016,
      "learning_rate": 3.138123359580052e-05,
      "loss": 0.3435,
      "step": 7950
    },
    {
      "epoch": 2.9996250468691414,
      "grad_norm": 0.06892984360456467,
      "learning_rate": 3.12640607424072e-05,
      "loss": 0.3239,
      "step": 8000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.892,
      "eval_f1_score": 0.8435571791205622,
      "eval_loss": 0.37355726957321167,
      "eval_runtime": 2.9824,
      "eval_samples_per_second": 670.599,
      "eval_steps_per_second": 111.99,
      "step": 8001
    },
    {
      "epoch": 3.0183727034120733,
      "grad_norm": 39.63288116455078,
      "learning_rate": 3.1146887889013875e-05,
      "loss": 0.3618,
      "step": 8050
    },
    {
      "epoch": 3.0371203599550056,
      "grad_norm": 74.73418426513672,
      "learning_rate": 3.102971503562055e-05,
      "loss": 0.2966,
      "step": 8100
    },
    {
      "epoch": 3.055868016497938,
      "grad_norm": 0.4955248534679413,
      "learning_rate": 3.091254218222722e-05,
      "loss": 0.2317,
      "step": 8150
    },
    {
      "epoch": 3.07461567304087,
      "grad_norm": 18.940044403076172,
      "learning_rate": 3.079536932883389e-05,
      "loss": 0.236,
      "step": 8200
    },
    {
      "epoch": 3.093363329583802,
      "grad_norm": 0.10892202705144882,
      "learning_rate": 3.067819647544057e-05,
      "loss": 0.2385,
      "step": 8250
    },
    {
      "epoch": 3.112110986126734,
      "grad_norm": 2.3945670127868652,
      "learning_rate": 3.0561023622047245e-05,
      "loss": 0.243,
      "step": 8300
    },
    {
      "epoch": 3.1308586426696663,
      "grad_norm": 27.01190757751465,
      "learning_rate": 3.044385076865392e-05,
      "loss": 0.3097,
      "step": 8350
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 54.272342681884766,
      "learning_rate": 3.0326677915260593e-05,
      "loss": 0.2751,
      "step": 8400
    },
    {
      "epoch": 3.1683539557555305,
      "grad_norm": 55.41367721557617,
      "learning_rate": 3.0209505061867266e-05,
      "loss": 0.3017,
      "step": 8450
    },
    {
      "epoch": 3.187101612298463,
      "grad_norm": 63.09538269042969,
      "learning_rate": 3.0092332208473945e-05,
      "loss": 0.3076,
      "step": 8500
    },
    {
      "epoch": 3.2058492688413947,
      "grad_norm": 33.337100982666016,
      "learning_rate": 2.9975159355080618e-05,
      "loss": 0.3472,
      "step": 8550
    },
    {
      "epoch": 3.224596925384327,
      "grad_norm": 1.5366493463516235,
      "learning_rate": 2.985798650168729e-05,
      "loss": 0.2384,
      "step": 8600
    },
    {
      "epoch": 3.2433445819272593,
      "grad_norm": 4.206017971038818,
      "learning_rate": 2.9740813648293963e-05,
      "loss": 0.2506,
      "step": 8650
    },
    {
      "epoch": 3.262092238470191,
      "grad_norm": 0.9314805269241333,
      "learning_rate": 2.9623640794900636e-05,
      "loss": 0.2946,
      "step": 8700
    },
    {
      "epoch": 3.2808398950131235,
      "grad_norm": 35.55076599121094,
      "learning_rate": 2.9506467941507315e-05,
      "loss": 0.2156,
      "step": 8750
    },
    {
      "epoch": 3.2995875515560553,
      "grad_norm": 27.126874923706055,
      "learning_rate": 2.9389295088113988e-05,
      "loss": 0.3827,
      "step": 8800
    },
    {
      "epoch": 3.3183352080989876,
      "grad_norm": 6.654202461242676,
      "learning_rate": 2.927212223472066e-05,
      "loss": 0.2311,
      "step": 8850
    },
    {
      "epoch": 3.33708286464192,
      "grad_norm": 0.6904062032699585,
      "learning_rate": 2.9154949381327333e-05,
      "loss": 0.2547,
      "step": 8900
    },
    {
      "epoch": 3.355830521184852,
      "grad_norm": 0.6234229207038879,
      "learning_rate": 2.903777652793401e-05,
      "loss": 0.3477,
      "step": 8950
    },
    {
      "epoch": 3.374578177727784,
      "grad_norm": 0.15615834295749664,
      "learning_rate": 2.8920603674540685e-05,
      "loss": 0.3594,
      "step": 9000
    },
    {
      "epoch": 3.393325834270716,
      "grad_norm": 0.14607113599777222,
      "learning_rate": 2.8803430821147358e-05,
      "loss": 0.3483,
      "step": 9050
    },
    {
      "epoch": 3.4120734908136483,
      "grad_norm": 3.709413528442383,
      "learning_rate": 2.8686257967754034e-05,
      "loss": 0.342,
      "step": 9100
    },
    {
      "epoch": 3.4308211473565806,
      "grad_norm": 0.3947467803955078,
      "learning_rate": 2.8569085114360706e-05,
      "loss": 0.3104,
      "step": 9150
    },
    {
      "epoch": 3.4495688038995125,
      "grad_norm": 21.114017486572266,
      "learning_rate": 2.845191226096738e-05,
      "loss": 0.1983,
      "step": 9200
    },
    {
      "epoch": 3.468316460442445,
      "grad_norm": 19.9197940826416,
      "learning_rate": 2.8334739407574058e-05,
      "loss": 0.5377,
      "step": 9250
    },
    {
      "epoch": 3.4870641169853767,
      "grad_norm": 2.424820899963379,
      "learning_rate": 2.821756655418073e-05,
      "loss": 0.2192,
      "step": 9300
    },
    {
      "epoch": 3.505811773528309,
      "grad_norm": 0.15592068433761597,
      "learning_rate": 2.8100393700787403e-05,
      "loss": 0.3177,
      "step": 9350
    },
    {
      "epoch": 3.524559430071241,
      "grad_norm": 31.832754135131836,
      "learning_rate": 2.7983220847394076e-05,
      "loss": 0.5133,
      "step": 9400
    },
    {
      "epoch": 3.543307086614173,
      "grad_norm": 38.13824462890625,
      "learning_rate": 2.786604799400075e-05,
      "loss": 0.3312,
      "step": 9450
    },
    {
      "epoch": 3.5620547431571055,
      "grad_norm": 0.12500707805156708,
      "learning_rate": 2.7748875140607428e-05,
      "loss": 0.3105,
      "step": 9500
    },
    {
      "epoch": 3.5808023997000373,
      "grad_norm": 34.870033264160156,
      "learning_rate": 2.76317022872141e-05,
      "loss": 0.3226,
      "step": 9550
    },
    {
      "epoch": 3.5995500562429696,
      "grad_norm": 0.34878209233283997,
      "learning_rate": 2.7514529433820773e-05,
      "loss": 0.3146,
      "step": 9600
    },
    {
      "epoch": 3.6182977127859015,
      "grad_norm": 2.8057608604431152,
      "learning_rate": 2.7397356580427446e-05,
      "loss": 0.2576,
      "step": 9650
    },
    {
      "epoch": 3.637045369328834,
      "grad_norm": 27.211793899536133,
      "learning_rate": 2.728018372703412e-05,
      "loss": 0.2776,
      "step": 9700
    },
    {
      "epoch": 3.655793025871766,
      "grad_norm": 1.2619328498840332,
      "learning_rate": 2.7163010873640798e-05,
      "loss": 0.3294,
      "step": 9750
    },
    {
      "epoch": 3.674540682414698,
      "grad_norm": 2.2383015155792236,
      "learning_rate": 2.704583802024747e-05,
      "loss": 0.3543,
      "step": 9800
    },
    {
      "epoch": 3.6932883389576303,
      "grad_norm": 34.510963439941406,
      "learning_rate": 2.6928665166854143e-05,
      "loss": 0.3071,
      "step": 9850
    },
    {
      "epoch": 3.712035995500562,
      "grad_norm": 0.727643609046936,
      "learning_rate": 2.681149231346082e-05,
      "loss": 0.3259,
      "step": 9900
    },
    {
      "epoch": 3.7307836520434945,
      "grad_norm": 42.48317337036133,
      "learning_rate": 2.6694319460067492e-05,
      "loss": 0.2907,
      "step": 9950
    },
    {
      "epoch": 3.749531308586427,
      "grad_norm": 18.292131423950195,
      "learning_rate": 2.6577146606674168e-05,
      "loss": 0.2266,
      "step": 10000
    },
    {
      "epoch": 3.7682789651293587,
      "grad_norm": 14.572577476501465,
      "learning_rate": 2.6459973753280844e-05,
      "loss": 0.237,
      "step": 10050
    },
    {
      "epoch": 3.787026621672291,
      "grad_norm": 36.154544830322266,
      "learning_rate": 2.6342800899887516e-05,
      "loss": 0.3581,
      "step": 10100
    },
    {
      "epoch": 3.805774278215223,
      "grad_norm": 0.6003691554069519,
      "learning_rate": 2.622562804649419e-05,
      "loss": 0.2988,
      "step": 10150
    },
    {
      "epoch": 3.824521934758155,
      "grad_norm": 37.42247009277344,
      "learning_rate": 2.6110798650168726e-05,
      "loss": 0.3768,
      "step": 10200
    },
    {
      "epoch": 3.8432695913010875,
      "grad_norm": 23.710357666015625,
      "learning_rate": 2.5993625796775406e-05,
      "loss": 0.2573,
      "step": 10250
    },
    {
      "epoch": 3.8620172478440193,
      "grad_norm": 0.9429317712783813,
      "learning_rate": 2.587645294338208e-05,
      "loss": 0.362,
      "step": 10300
    },
    {
      "epoch": 3.8807649043869517,
      "grad_norm": 6.484644412994385,
      "learning_rate": 2.575928008998875e-05,
      "loss": 0.2387,
      "step": 10350
    },
    {
      "epoch": 3.8995125609298835,
      "grad_norm": 1.694339632987976,
      "learning_rate": 2.5642107236595424e-05,
      "loss": 0.2304,
      "step": 10400
    },
    {
      "epoch": 3.918260217472816,
      "grad_norm": 34.42285919189453,
      "learning_rate": 2.5524934383202103e-05,
      "loss": 0.298,
      "step": 10450
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 0.2683822512626648,
      "learning_rate": 2.5407761529808776e-05,
      "loss": 0.2816,
      "step": 10500
    },
    {
      "epoch": 3.95575553055868,
      "grad_norm": 0.07468897849321365,
      "learning_rate": 2.5290588676415448e-05,
      "loss": 0.2686,
      "step": 10550
    },
    {
      "epoch": 3.9745031871016123,
      "grad_norm": 36.49374008178711,
      "learning_rate": 2.5173415823022124e-05,
      "loss": 0.449,
      "step": 10600
    },
    {
      "epoch": 3.993250843644544,
      "grad_norm": 3.6752090454101562,
      "learning_rate": 2.5056242969628797e-05,
      "loss": 0.2602,
      "step": 10650
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.897,
      "eval_f1_score": 0.8466932601419126,
      "eval_loss": 0.38120657205581665,
      "eval_runtime": 2.1527,
      "eval_samples_per_second": 929.07,
      "eval_steps_per_second": 155.155,
      "step": 10668
    },
    {
      "epoch": 4.0119985001874765,
      "grad_norm": 1.8129841089248657,
      "learning_rate": 2.4939070116235473e-05,
      "loss": 0.2602,
      "step": 10700
    },
    {
      "epoch": 4.030746156730409,
      "grad_norm": 0.03722082078456879,
      "learning_rate": 2.4821897262842145e-05,
      "loss": 0.266,
      "step": 10750
    },
    {
      "epoch": 4.049493813273341,
      "grad_norm": 25.746187210083008,
      "learning_rate": 2.470472440944882e-05,
      "loss": 0.3023,
      "step": 10800
    },
    {
      "epoch": 4.0682414698162725,
      "grad_norm": 0.05428322032094002,
      "learning_rate": 2.4587551556055494e-05,
      "loss": 0.2589,
      "step": 10850
    },
    {
      "epoch": 4.086989126359205,
      "grad_norm": 83.86540222167969,
      "learning_rate": 2.447037870266217e-05,
      "loss": 0.2131,
      "step": 10900
    },
    {
      "epoch": 4.105736782902137,
      "grad_norm": 64.21054077148438,
      "learning_rate": 2.4353205849268843e-05,
      "loss": 0.2313,
      "step": 10950
    },
    {
      "epoch": 4.1244844394450695,
      "grad_norm": 0.032128337770700455,
      "learning_rate": 2.4236032995875515e-05,
      "loss": 0.2104,
      "step": 11000
    },
    {
      "epoch": 4.143232095988002,
      "grad_norm": 52.364952087402344,
      "learning_rate": 2.411886014248219e-05,
      "loss": 0.3057,
      "step": 11050
    },
    {
      "epoch": 4.161979752530933,
      "grad_norm": 48.180660247802734,
      "learning_rate": 2.4001687289088864e-05,
      "loss": 0.27,
      "step": 11100
    },
    {
      "epoch": 4.1807274090738655,
      "grad_norm": 0.07398132234811783,
      "learning_rate": 2.388451443569554e-05,
      "loss": 0.2874,
      "step": 11150
    },
    {
      "epoch": 4.199475065616798,
      "grad_norm": 0.10157114267349243,
      "learning_rate": 2.3767341582302213e-05,
      "loss": 0.2905,
      "step": 11200
    },
    {
      "epoch": 4.21822272215973,
      "grad_norm": 0.075553297996521,
      "learning_rate": 2.3650168728908885e-05,
      "loss": 0.1275,
      "step": 11250
    },
    {
      "epoch": 4.2369703787026625,
      "grad_norm": 89.7148208618164,
      "learning_rate": 2.353299587551556e-05,
      "loss": 0.2961,
      "step": 11300
    },
    {
      "epoch": 4.255718035245594,
      "grad_norm": 38.43242645263672,
      "learning_rate": 2.3415823022122234e-05,
      "loss": 0.4369,
      "step": 11350
    },
    {
      "epoch": 4.274465691788526,
      "grad_norm": 1.6233991384506226,
      "learning_rate": 2.329865016872891e-05,
      "loss": 0.2082,
      "step": 11400
    },
    {
      "epoch": 4.2932133483314585,
      "grad_norm": 39.85319137573242,
      "learning_rate": 2.3181477315335582e-05,
      "loss": 0.3092,
      "step": 11450
    },
    {
      "epoch": 4.311961004874391,
      "grad_norm": 83.11163330078125,
      "learning_rate": 2.306430446194226e-05,
      "loss": 0.3649,
      "step": 11500
    },
    {
      "epoch": 4.330708661417323,
      "grad_norm": 0.3130379021167755,
      "learning_rate": 2.2947131608548934e-05,
      "loss": 0.2907,
      "step": 11550
    },
    {
      "epoch": 4.349456317960255,
      "grad_norm": 13.428464889526367,
      "learning_rate": 2.2829958755155607e-05,
      "loss": 0.2731,
      "step": 11600
    },
    {
      "epoch": 4.368203974503187,
      "grad_norm": 21.8580265045166,
      "learning_rate": 2.2712785901762283e-05,
      "loss": 0.2817,
      "step": 11650
    },
    {
      "epoch": 4.386951631046119,
      "grad_norm": 2.071316719055176,
      "learning_rate": 2.2595613048368956e-05,
      "loss": 0.3401,
      "step": 11700
    },
    {
      "epoch": 4.4056992875890515,
      "grad_norm": 32.453712463378906,
      "learning_rate": 2.247844019497563e-05,
      "loss": 0.3474,
      "step": 11750
    },
    {
      "epoch": 4.424446944131984,
      "grad_norm": 31.900964736938477,
      "learning_rate": 2.2361267341582304e-05,
      "loss": 0.3345,
      "step": 11800
    },
    {
      "epoch": 4.443194600674915,
      "grad_norm": 4.774083137512207,
      "learning_rate": 2.2244094488188977e-05,
      "loss": 0.2544,
      "step": 11850
    },
    {
      "epoch": 4.4619422572178475,
      "grad_norm": 68.94773864746094,
      "learning_rate": 2.2126921634795653e-05,
      "loss": 0.1527,
      "step": 11900
    },
    {
      "epoch": 4.48068991376078,
      "grad_norm": 0.03710903599858284,
      "learning_rate": 2.2009748781402326e-05,
      "loss": 0.2357,
      "step": 11950
    },
    {
      "epoch": 4.499437570303712,
      "grad_norm": 2.356743097305298,
      "learning_rate": 2.1892575928008998e-05,
      "loss": 0.2488,
      "step": 12000
    },
    {
      "epoch": 4.5181852268466445,
      "grad_norm": 90.68397521972656,
      "learning_rate": 2.1775403074615674e-05,
      "loss": 0.2635,
      "step": 12050
    },
    {
      "epoch": 4.536932883389577,
      "grad_norm": 0.03216139227151871,
      "learning_rate": 2.1658230221222347e-05,
      "loss": 0.2589,
      "step": 12100
    },
    {
      "epoch": 4.555680539932508,
      "grad_norm": 0.17059651017189026,
      "learning_rate": 2.1541057367829023e-05,
      "loss": 0.2961,
      "step": 12150
    },
    {
      "epoch": 4.5744281964754405,
      "grad_norm": 0.024536199867725372,
      "learning_rate": 2.1423884514435695e-05,
      "loss": 0.2208,
      "step": 12200
    },
    {
      "epoch": 4.593175853018373,
      "grad_norm": 29.05754280090332,
      "learning_rate": 2.1306711661042368e-05,
      "loss": 0.2594,
      "step": 12250
    },
    {
      "epoch": 4.611923509561305,
      "grad_norm": 0.037884101271629333,
      "learning_rate": 2.1191882264716912e-05,
      "loss": 0.2571,
      "step": 12300
    },
    {
      "epoch": 4.6306711661042375,
      "grad_norm": 30.731502532958984,
      "learning_rate": 2.1074709411323585e-05,
      "loss": 0.2102,
      "step": 12350
    },
    {
      "epoch": 4.649418822647169,
      "grad_norm": 41.195404052734375,
      "learning_rate": 2.095753655793026e-05,
      "loss": 0.236,
      "step": 12400
    },
    {
      "epoch": 4.668166479190101,
      "grad_norm": 3.9469854831695557,
      "learning_rate": 2.0840363704536933e-05,
      "loss": 0.2671,
      "step": 12450
    },
    {
      "epoch": 4.6869141357330335,
      "grad_norm": 0.05064068362116814,
      "learning_rate": 2.072319085114361e-05,
      "loss": 0.2963,
      "step": 12500
    },
    {
      "epoch": 4.705661792275966,
      "grad_norm": 22.10988426208496,
      "learning_rate": 2.0606017997750282e-05,
      "loss": 0.3654,
      "step": 12550
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 25.438566207885742,
      "learning_rate": 2.0488845144356955e-05,
      "loss": 0.2508,
      "step": 12600
    },
    {
      "epoch": 4.7431571053618296,
      "grad_norm": 0.17611368000507355,
      "learning_rate": 2.037167229096363e-05,
      "loss": 0.2525,
      "step": 12650
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.060514796525239944,
      "learning_rate": 2.0254499437570303e-05,
      "loss": 0.2404,
      "step": 12700
    },
    {
      "epoch": 4.780652418447694,
      "grad_norm": 18.625858306884766,
      "learning_rate": 2.013732658417698e-05,
      "loss": 0.3463,
      "step": 12750
    },
    {
      "epoch": 4.7994000749906265,
      "grad_norm": 4.616847038269043,
      "learning_rate": 2.0020153730783652e-05,
      "loss": 0.2892,
      "step": 12800
    },
    {
      "epoch": 4.818147731533559,
      "grad_norm": 14.343350410461426,
      "learning_rate": 1.9902980877390324e-05,
      "loss": 0.3329,
      "step": 12850
    },
    {
      "epoch": 4.83689538807649,
      "grad_norm": 18.642574310302734,
      "learning_rate": 1.9785808023997e-05,
      "loss": 0.3012,
      "step": 12900
    },
    {
      "epoch": 4.8556430446194225,
      "grad_norm": 0.04889765754342079,
      "learning_rate": 1.9668635170603673e-05,
      "loss": 0.2886,
      "step": 12950
    },
    {
      "epoch": 4.874390701162355,
      "grad_norm": 19.4702091217041,
      "learning_rate": 1.955146231721035e-05,
      "loss": 0.2844,
      "step": 13000
    },
    {
      "epoch": 4.893138357705287,
      "grad_norm": 1.7358319759368896,
      "learning_rate": 1.9434289463817025e-05,
      "loss": 0.2563,
      "step": 13050
    },
    {
      "epoch": 4.9118860142482195,
      "grad_norm": 64.02737426757812,
      "learning_rate": 1.9317116610423698e-05,
      "loss": 0.1662,
      "step": 13100
    },
    {
      "epoch": 4.930633670791151,
      "grad_norm": 0.03628009930253029,
      "learning_rate": 1.9199943757030374e-05,
      "loss": 0.2869,
      "step": 13150
    },
    {
      "epoch": 4.949381327334083,
      "grad_norm": 31.82955551147461,
      "learning_rate": 1.9082770903637046e-05,
      "loss": 0.1625,
      "step": 13200
    },
    {
      "epoch": 4.9681289838770155,
      "grad_norm": 3.983811378479004,
      "learning_rate": 1.8965598050243722e-05,
      "loss": 0.2934,
      "step": 13250
    },
    {
      "epoch": 4.986876640419948,
      "grad_norm": 56.174617767333984,
      "learning_rate": 1.8848425196850395e-05,
      "loss": 0.3459,
      "step": 13300
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9015,
      "eval_f1_score": 0.8563442660642638,
      "eval_loss": 0.3686979115009308,
      "eval_runtime": 1.7982,
      "eval_samples_per_second": 1112.222,
      "eval_steps_per_second": 185.741,
      "step": 13335
    },
    {
      "epoch": 5.005624296962879,
      "grad_norm": 38.982547760009766,
      "learning_rate": 1.8731252343457068e-05,
      "loss": 0.2901,
      "step": 13350
    },
    {
      "epoch": 5.024371953505812,
      "grad_norm": 41.560508728027344,
      "learning_rate": 1.8614079490063744e-05,
      "loss": 0.2827,
      "step": 13400
    },
    {
      "epoch": 5.043119610048744,
      "grad_norm": 47.04405212402344,
      "learning_rate": 1.8496906636670416e-05,
      "loss": 0.194,
      "step": 13450
    },
    {
      "epoch": 5.061867266591676,
      "grad_norm": 2.960601568222046,
      "learning_rate": 1.8379733783277092e-05,
      "loss": 0.2089,
      "step": 13500
    },
    {
      "epoch": 5.0806149231346085,
      "grad_norm": 0.028649790212512016,
      "learning_rate": 1.8262560929883765e-05,
      "loss": 0.2616,
      "step": 13550
    },
    {
      "epoch": 5.09936257967754,
      "grad_norm": 15.303803443908691,
      "learning_rate": 1.8145388076490437e-05,
      "loss": 0.2218,
      "step": 13600
    },
    {
      "epoch": 5.118110236220472,
      "grad_norm": 0.2674214243888855,
      "learning_rate": 1.8028215223097113e-05,
      "loss": 0.2684,
      "step": 13650
    },
    {
      "epoch": 5.1368578927634045,
      "grad_norm": 0.08562518656253815,
      "learning_rate": 1.7913385826771654e-05,
      "loss": 0.2478,
      "step": 13700
    },
    {
      "epoch": 5.155605549306337,
      "grad_norm": 29.674976348876953,
      "learning_rate": 1.779621297337833e-05,
      "loss": 0.3847,
      "step": 13750
    },
    {
      "epoch": 5.174353205849269,
      "grad_norm": 0.04050913080573082,
      "learning_rate": 1.7679040119985003e-05,
      "loss": 0.2127,
      "step": 13800
    },
    {
      "epoch": 5.193100862392201,
      "grad_norm": 62.35906982421875,
      "learning_rate": 1.756186726659168e-05,
      "loss": 0.28,
      "step": 13850
    },
    {
      "epoch": 5.211848518935133,
      "grad_norm": 0.08738244324922562,
      "learning_rate": 1.744469441319835e-05,
      "loss": 0.3298,
      "step": 13900
    },
    {
      "epoch": 5.230596175478065,
      "grad_norm": 0.25098368525505066,
      "learning_rate": 1.7327521559805024e-05,
      "loss": 0.2341,
      "step": 13950
    },
    {
      "epoch": 5.2493438320209975,
      "grad_norm": 31.971996307373047,
      "learning_rate": 1.72103487064117e-05,
      "loss": 0.2105,
      "step": 14000
    },
    {
      "epoch": 5.26809148856393,
      "grad_norm": 39.48352813720703,
      "learning_rate": 1.7093175853018373e-05,
      "loss": 0.2247,
      "step": 14050
    },
    {
      "epoch": 5.286839145106861,
      "grad_norm": 0.0610496811568737,
      "learning_rate": 1.697600299962505e-05,
      "loss": 0.2673,
      "step": 14100
    },
    {
      "epoch": 5.305586801649794,
      "grad_norm": 32.168846130371094,
      "learning_rate": 1.685883014623172e-05,
      "loss": 0.1646,
      "step": 14150
    },
    {
      "epoch": 5.324334458192726,
      "grad_norm": 26.42202377319336,
      "learning_rate": 1.6741657292838394e-05,
      "loss": 0.2215,
      "step": 14200
    },
    {
      "epoch": 5.343082114735658,
      "grad_norm": 17.668237686157227,
      "learning_rate": 1.662448443944507e-05,
      "loss": 0.2062,
      "step": 14250
    },
    {
      "epoch": 5.3618297712785905,
      "grad_norm": 0.04773595929145813,
      "learning_rate": 1.6507311586051742e-05,
      "loss": 0.1126,
      "step": 14300
    },
    {
      "epoch": 5.380577427821522,
      "grad_norm": 0.09489496052265167,
      "learning_rate": 1.639013873265842e-05,
      "loss": 0.215,
      "step": 14350
    },
    {
      "epoch": 5.399325084364454,
      "grad_norm": 0.057800158858299255,
      "learning_rate": 1.627296587926509e-05,
      "loss": 0.2894,
      "step": 14400
    },
    {
      "epoch": 5.4180727409073866,
      "grad_norm": 4.208338737487793,
      "learning_rate": 1.6155793025871767e-05,
      "loss": 0.288,
      "step": 14450
    },
    {
      "epoch": 5.436820397450319,
      "grad_norm": 5.812273025512695,
      "learning_rate": 1.603862017247844e-05,
      "loss": 0.2759,
      "step": 14500
    },
    {
      "epoch": 5.455568053993251,
      "grad_norm": 0.06663317233324051,
      "learning_rate": 1.5921447319085116e-05,
      "loss": 0.2957,
      "step": 14550
    },
    {
      "epoch": 5.474315710536183,
      "grad_norm": 0.839546799659729,
      "learning_rate": 1.5804274465691792e-05,
      "loss": 0.2048,
      "step": 14600
    },
    {
      "epoch": 5.493063367079115,
      "grad_norm": 11.660568237304688,
      "learning_rate": 1.5687101612298464e-05,
      "loss": 0.1945,
      "step": 14650
    },
    {
      "epoch": 5.511811023622047,
      "grad_norm": 0.15377312898635864,
      "learning_rate": 1.5569928758905137e-05,
      "loss": 0.2382,
      "step": 14700
    },
    {
      "epoch": 5.5305586801649795,
      "grad_norm": 0.09175804257392883,
      "learning_rate": 1.5452755905511813e-05,
      "loss": 0.2694,
      "step": 14750
    },
    {
      "epoch": 5.549306336707912,
      "grad_norm": 0.27607452869415283,
      "learning_rate": 1.5335583052118486e-05,
      "loss": 0.276,
      "step": 14800
    },
    {
      "epoch": 5.568053993250843,
      "grad_norm": 38.804744720458984,
      "learning_rate": 1.5218410198725162e-05,
      "loss": 0.3949,
      "step": 14850
    },
    {
      "epoch": 5.586801649793776,
      "grad_norm": 0.09345920383930206,
      "learning_rate": 1.5101237345331834e-05,
      "loss": 0.2167,
      "step": 14900
    },
    {
      "epoch": 5.605549306336708,
      "grad_norm": 0.036399368196725845,
      "learning_rate": 1.4984064491938507e-05,
      "loss": 0.2199,
      "step": 14950
    },
    {
      "epoch": 5.62429696287964,
      "grad_norm": 0.025129863992333412,
      "learning_rate": 1.4866891638545183e-05,
      "loss": 0.242,
      "step": 15000
    },
    {
      "epoch": 5.6430446194225725,
      "grad_norm": 0.08919689804315567,
      "learning_rate": 1.4749718785151855e-05,
      "loss": 0.2719,
      "step": 15050
    },
    {
      "epoch": 5.661792275965504,
      "grad_norm": 0.8732050061225891,
      "learning_rate": 1.4632545931758531e-05,
      "loss": 0.1606,
      "step": 15100
    },
    {
      "epoch": 5.680539932508436,
      "grad_norm": 43.90478515625,
      "learning_rate": 1.4515373078365204e-05,
      "loss": 0.1585,
      "step": 15150
    },
    {
      "epoch": 5.699287589051369,
      "grad_norm": 32.73868942260742,
      "learning_rate": 1.439820022497188e-05,
      "loss": 0.3289,
      "step": 15200
    },
    {
      "epoch": 5.718035245594301,
      "grad_norm": 10.885466575622559,
      "learning_rate": 1.4281027371578554e-05,
      "loss": 0.3796,
      "step": 15250
    },
    {
      "epoch": 5.736782902137233,
      "grad_norm": 60.16195297241211,
      "learning_rate": 1.4163854518185227e-05,
      "loss": 0.3178,
      "step": 15300
    },
    {
      "epoch": 5.755530558680165,
      "grad_norm": 2.180835247039795,
      "learning_rate": 1.4046681664791903e-05,
      "loss": 0.3067,
      "step": 15350
    },
    {
      "epoch": 5.774278215223097,
      "grad_norm": 67.09991455078125,
      "learning_rate": 1.3929508811398576e-05,
      "loss": 0.2528,
      "step": 15400
    },
    {
      "epoch": 5.793025871766029,
      "grad_norm": 27.671340942382812,
      "learning_rate": 1.3812335958005252e-05,
      "loss": 0.2337,
      "step": 15450
    },
    {
      "epoch": 5.8117735283089615,
      "grad_norm": 0.01925436034798622,
      "learning_rate": 1.3695163104611924e-05,
      "loss": 0.186,
      "step": 15500
    },
    {
      "epoch": 5.830521184851894,
      "grad_norm": 33.39337158203125,
      "learning_rate": 1.3577990251218597e-05,
      "loss": 0.2149,
      "step": 15550
    },
    {
      "epoch": 5.849268841394825,
      "grad_norm": 0.0191473551094532,
      "learning_rate": 1.3460817397825273e-05,
      "loss": 0.28,
      "step": 15600
    },
    {
      "epoch": 5.868016497937758,
      "grad_norm": 2.325803756713867,
      "learning_rate": 1.3343644544431946e-05,
      "loss": 0.193,
      "step": 15650
    },
    {
      "epoch": 5.88676415448069,
      "grad_norm": 0.2219303548336029,
      "learning_rate": 1.3226471691038622e-05,
      "loss": 0.3105,
      "step": 15700
    },
    {
      "epoch": 5.905511811023622,
      "grad_norm": 0.6409505605697632,
      "learning_rate": 1.3109298837645296e-05,
      "loss": 0.2174,
      "step": 15750
    },
    {
      "epoch": 5.9242594675665545,
      "grad_norm": 0.14914429187774658,
      "learning_rate": 1.2992125984251968e-05,
      "loss": 0.301,
      "step": 15800
    },
    {
      "epoch": 5.943007124109486,
      "grad_norm": 1.1806597709655762,
      "learning_rate": 1.2874953130858644e-05,
      "loss": 0.2321,
      "step": 15850
    },
    {
      "epoch": 5.961754780652418,
      "grad_norm": 0.15524928271770477,
      "learning_rate": 1.2757780277465317e-05,
      "loss": 0.1524,
      "step": 15900
    },
    {
      "epoch": 5.980502437195351,
      "grad_norm": 24.117246627807617,
      "learning_rate": 1.2640607424071993e-05,
      "loss": 0.3053,
      "step": 15950
    },
    {
      "epoch": 5.999250093738283,
      "grad_norm": 0.37517961859703064,
      "learning_rate": 1.2523434570678666e-05,
      "loss": 0.2377,
      "step": 16000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9075,
      "eval_f1_score": 0.8598967750990423,
      "eval_loss": 0.35876330733299255,
      "eval_runtime": 1.8689,
      "eval_samples_per_second": 1070.13,
      "eval_steps_per_second": 178.712,
      "step": 16002
    },
    {
      "epoch": 6.017997750281215,
      "grad_norm": 0.019903622567653656,
      "learning_rate": 1.240626171728534e-05,
      "loss": 0.1773,
      "step": 16050
    },
    {
      "epoch": 6.036745406824147,
      "grad_norm": 26.35521697998047,
      "learning_rate": 1.2289088863892013e-05,
      "loss": 0.1957,
      "step": 16100
    },
    {
      "epoch": 6.055493063367079,
      "grad_norm": 15.764660835266113,
      "learning_rate": 1.2171916010498689e-05,
      "loss": 0.1828,
      "step": 16150
    },
    {
      "epoch": 6.074240719910011,
      "grad_norm": 36.6107177734375,
      "learning_rate": 1.2054743157105363e-05,
      "loss": 0.2272,
      "step": 16200
    },
    {
      "epoch": 6.0929883764529436,
      "grad_norm": 0.027394218370318413,
      "learning_rate": 1.1937570303712037e-05,
      "loss": 0.1795,
      "step": 16250
    },
    {
      "epoch": 6.111736032995876,
      "grad_norm": 116.7557601928711,
      "learning_rate": 1.1820397450318712e-05,
      "loss": 0.2981,
      "step": 16300
    },
    {
      "epoch": 6.130483689538807,
      "grad_norm": 0.42633965611457825,
      "learning_rate": 1.1703224596925384e-05,
      "loss": 0.2312,
      "step": 16350
    },
    {
      "epoch": 6.14923134608174,
      "grad_norm": 23.86686134338379,
      "learning_rate": 1.1586051743532059e-05,
      "loss": 0.1344,
      "step": 16400
    },
    {
      "epoch": 6.167979002624672,
      "grad_norm": 0.3916255533695221,
      "learning_rate": 1.1468878890138733e-05,
      "loss": 0.1994,
      "step": 16450
    },
    {
      "epoch": 6.186726659167604,
      "grad_norm": 62.50461959838867,
      "learning_rate": 1.1351706036745407e-05,
      "loss": 0.2115,
      "step": 16500
    },
    {
      "epoch": 6.2054743157105365,
      "grad_norm": 1.0082365274429321,
      "learning_rate": 1.1234533183352081e-05,
      "loss": 0.1705,
      "step": 16550
    },
    {
      "epoch": 6.224221972253468,
      "grad_norm": 89.0617904663086,
      "learning_rate": 1.1117360329958756e-05,
      "loss": 0.2203,
      "step": 16600
    },
    {
      "epoch": 6.2429696287964,
      "grad_norm": 3.8722307682037354,
      "learning_rate": 1.100018747656543e-05,
      "loss": 0.2393,
      "step": 16650
    },
    {
      "epoch": 6.261717285339333,
      "grad_norm": 0.08795388042926788,
      "learning_rate": 1.0883014623172104e-05,
      "loss": 0.1976,
      "step": 16700
    },
    {
      "epoch": 6.280464941882265,
      "grad_norm": 0.01845274679362774,
      "learning_rate": 1.0765841769778779e-05,
      "loss": 0.2035,
      "step": 16750
    },
    {
      "epoch": 6.299212598425197,
      "grad_norm": 0.0387389175593853,
      "learning_rate": 1.0648668916385453e-05,
      "loss": 0.2661,
      "step": 16800
    },
    {
      "epoch": 6.317960254968129,
      "grad_norm": 0.01452722866088152,
      "learning_rate": 1.0531496062992126e-05,
      "loss": 0.1381,
      "step": 16850
    },
    {
      "epoch": 6.336707911511061,
      "grad_norm": 0.023036789149045944,
      "learning_rate": 1.04143232095988e-05,
      "loss": 0.2832,
      "step": 16900
    },
    {
      "epoch": 6.355455568053993,
      "grad_norm": 0.024891559034585953,
      "learning_rate": 1.0297150356205474e-05,
      "loss": 0.2031,
      "step": 16950
    },
    {
      "epoch": 6.374203224596926,
      "grad_norm": 22.849239349365234,
      "learning_rate": 1.0179977502812149e-05,
      "loss": 0.1775,
      "step": 17000
    },
    {
      "epoch": 6.392950881139858,
      "grad_norm": 27.114181518554688,
      "learning_rate": 1.0062804649418823e-05,
      "loss": 0.3383,
      "step": 17050
    },
    {
      "epoch": 6.411698537682789,
      "grad_norm": 0.3859938383102417,
      "learning_rate": 9.945631796025497e-06,
      "loss": 0.1732,
      "step": 17100
    },
    {
      "epoch": 6.430446194225722,
      "grad_norm": 58.46018981933594,
      "learning_rate": 9.828458942632172e-06,
      "loss": 0.2152,
      "step": 17150
    },
    {
      "epoch": 6.449193850768654,
      "grad_norm": 0.04166395217180252,
      "learning_rate": 9.711286089238846e-06,
      "loss": 0.2564,
      "step": 17200
    },
    {
      "epoch": 6.467941507311586,
      "grad_norm": 73.4051284790039,
      "learning_rate": 9.59411323584552e-06,
      "loss": 0.2507,
      "step": 17250
    },
    {
      "epoch": 6.4866891638545185,
      "grad_norm": 0.034123241901397705,
      "learning_rate": 9.476940382452194e-06,
      "loss": 0.2598,
      "step": 17300
    },
    {
      "epoch": 6.50543682039745,
      "grad_norm": 1.7460416555404663,
      "learning_rate": 9.359767529058869e-06,
      "loss": 0.2062,
      "step": 17350
    },
    {
      "epoch": 6.524184476940382,
      "grad_norm": 111.5773696899414,
      "learning_rate": 9.242594675665541e-06,
      "loss": 0.2715,
      "step": 17400
    },
    {
      "epoch": 6.542932133483315,
      "grad_norm": 0.015276974998414516,
      "learning_rate": 9.125421822272216e-06,
      "loss": 0.1694,
      "step": 17450
    },
    {
      "epoch": 6.561679790026247,
      "grad_norm": 6.222506046295166,
      "learning_rate": 9.00824896887889e-06,
      "loss": 0.1818,
      "step": 17500
    },
    {
      "epoch": 6.580427446569179,
      "grad_norm": 0.05632907897233963,
      "learning_rate": 8.891076115485564e-06,
      "loss": 0.1631,
      "step": 17550
    },
    {
      "epoch": 6.599175103112111,
      "grad_norm": 37.655765533447266,
      "learning_rate": 8.77390326209224e-06,
      "loss": 0.2066,
      "step": 17600
    },
    {
      "epoch": 6.617922759655043,
      "grad_norm": 6.974826812744141,
      "learning_rate": 8.656730408698913e-06,
      "loss": 0.2194,
      "step": 17650
    },
    {
      "epoch": 6.636670416197975,
      "grad_norm": 0.22492702305316925,
      "learning_rate": 8.539557555305587e-06,
      "loss": 0.3083,
      "step": 17700
    },
    {
      "epoch": 6.655418072740908,
      "grad_norm": 12.052948951721191,
      "learning_rate": 8.422384701912262e-06,
      "loss": 0.2507,
      "step": 17750
    },
    {
      "epoch": 6.67416572928384,
      "grad_norm": 1.5809420347213745,
      "learning_rate": 8.305211848518936e-06,
      "loss": 0.208,
      "step": 17800
    },
    {
      "epoch": 6.692913385826771,
      "grad_norm": 0.02036474272608757,
      "learning_rate": 8.190382452193477e-06,
      "loss": 0.212,
      "step": 17850
    },
    {
      "epoch": 6.711661042369704,
      "grad_norm": 0.03898285701870918,
      "learning_rate": 8.073209598800151e-06,
      "loss": 0.2328,
      "step": 17900
    },
    {
      "epoch": 6.730408698912636,
      "grad_norm": 23.285449981689453,
      "learning_rate": 7.956036745406825e-06,
      "loss": 0.2498,
      "step": 17950
    },
    {
      "epoch": 6.749156355455568,
      "grad_norm": 1.766892671585083,
      "learning_rate": 7.838863892013498e-06,
      "loss": 0.2049,
      "step": 18000
    },
    {
      "epoch": 6.767904011998501,
      "grad_norm": 83.35687255859375,
      "learning_rate": 7.721691038620172e-06,
      "loss": 0.2438,
      "step": 18050
    },
    {
      "epoch": 6.786651668541432,
      "grad_norm": 1.6967802047729492,
      "learning_rate": 7.604518185226847e-06,
      "loss": 0.2618,
      "step": 18100
    },
    {
      "epoch": 6.805399325084364,
      "grad_norm": 51.647674560546875,
      "learning_rate": 7.487345331833522e-06,
      "loss": 0.2051,
      "step": 18150
    },
    {
      "epoch": 6.824146981627297,
      "grad_norm": 0.04487907513976097,
      "learning_rate": 7.370172478440196e-06,
      "loss": 0.2467,
      "step": 18200
    },
    {
      "epoch": 6.842894638170229,
      "grad_norm": 33.269813537597656,
      "learning_rate": 7.252999625046869e-06,
      "loss": 0.2371,
      "step": 18250
    },
    {
      "epoch": 6.861642294713161,
      "grad_norm": 92.54754638671875,
      "learning_rate": 7.135826771653544e-06,
      "loss": 0.1818,
      "step": 18300
    },
    {
      "epoch": 6.880389951256093,
      "grad_norm": 74.75696563720703,
      "learning_rate": 7.018653918260218e-06,
      "loss": 0.3493,
      "step": 18350
    },
    {
      "epoch": 6.899137607799025,
      "grad_norm": 28.931026458740234,
      "learning_rate": 6.901481064866892e-06,
      "loss": 0.2486,
      "step": 18400
    },
    {
      "epoch": 6.917885264341957,
      "grad_norm": 3.9597039222717285,
      "learning_rate": 6.784308211473567e-06,
      "loss": 0.2916,
      "step": 18450
    },
    {
      "epoch": 6.93663292088489,
      "grad_norm": 60.5012321472168,
      "learning_rate": 6.66713535808024e-06,
      "loss": 0.247,
      "step": 18500
    },
    {
      "epoch": 6.955380577427822,
      "grad_norm": 0.33523619174957275,
      "learning_rate": 6.549962504686914e-06,
      "loss": 0.122,
      "step": 18550
    },
    {
      "epoch": 6.974128233970753,
      "grad_norm": 1.6866172552108765,
      "learning_rate": 6.432789651293589e-06,
      "loss": 0.2488,
      "step": 18600
    },
    {
      "epoch": 6.992875890513686,
      "grad_norm": 24.01080322265625,
      "learning_rate": 6.315616797900263e-06,
      "loss": 0.251,
      "step": 18650
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.902,
      "eval_f1_score": 0.8500360806771353,
      "eval_loss": 0.36570581793785095,
      "eval_runtime": 1.8833,
      "eval_samples_per_second": 1061.957,
      "eval_steps_per_second": 177.347,
      "step": 18669
    },
    {
      "epoch": 7.011623547056618,
      "grad_norm": 0.05704905092716217,
      "learning_rate": 6.1984439445069365e-06,
      "loss": 0.224,
      "step": 18700
    },
    {
      "epoch": 7.03037120359955,
      "grad_norm": 7.7361297607421875,
      "learning_rate": 6.081271091113612e-06,
      "loss": 0.1485,
      "step": 18750
    },
    {
      "epoch": 7.049118860142483,
      "grad_norm": 0.020573154091835022,
      "learning_rate": 5.964098237720285e-06,
      "loss": 0.2481,
      "step": 18800
    },
    {
      "epoch": 7.067866516685414,
      "grad_norm": 0.022822272032499313,
      "learning_rate": 5.8469253843269594e-06,
      "loss": 0.2451,
      "step": 18850
    },
    {
      "epoch": 7.086614173228346,
      "grad_norm": 0.06357936561107635,
      "learning_rate": 5.729752530933634e-06,
      "loss": 0.2822,
      "step": 18900
    },
    {
      "epoch": 7.105361829771279,
      "grad_norm": 0.01160330232232809,
      "learning_rate": 5.612579677540308e-06,
      "loss": 0.1522,
      "step": 18950
    },
    {
      "epoch": 7.124109486314211,
      "grad_norm": 22.173072814941406,
      "learning_rate": 5.495406824146982e-06,
      "loss": 0.194,
      "step": 19000
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 65.85819244384766,
      "learning_rate": 5.378233970753656e-06,
      "loss": 0.2079,
      "step": 19050
    },
    {
      "epoch": 7.161604799400075,
      "grad_norm": 0.022950809448957443,
      "learning_rate": 5.26106111736033e-06,
      "loss": 0.1656,
      "step": 19100
    },
    {
      "epoch": 7.180352455943007,
      "grad_norm": 33.87263107299805,
      "learning_rate": 5.1438882639670045e-06,
      "loss": 0.1793,
      "step": 19150
    },
    {
      "epoch": 7.199100112485939,
      "grad_norm": 0.05403962358832359,
      "learning_rate": 5.026715410573679e-06,
      "loss": 0.2529,
      "step": 19200
    },
    {
      "epoch": 7.217847769028872,
      "grad_norm": 77.98699188232422,
      "learning_rate": 4.909542557180353e-06,
      "loss": 0.1852,
      "step": 19250
    },
    {
      "epoch": 7.236595425571804,
      "grad_norm": 12.66622543334961,
      "learning_rate": 4.7923697037870265e-06,
      "loss": 0.1341,
      "step": 19300
    },
    {
      "epoch": 7.255343082114735,
      "grad_norm": 9.1878662109375,
      "learning_rate": 4.675196850393701e-06,
      "loss": 0.1887,
      "step": 19350
    },
    {
      "epoch": 7.274090738657668,
      "grad_norm": 0.02591683156788349,
      "learning_rate": 4.558023997000375e-06,
      "loss": 0.172,
      "step": 19400
    },
    {
      "epoch": 7.2928383952006,
      "grad_norm": 49.29936599731445,
      "learning_rate": 4.4408511436070495e-06,
      "loss": 0.2263,
      "step": 19450
    },
    {
      "epoch": 7.311586051743532,
      "grad_norm": 10.012870788574219,
      "learning_rate": 4.323678290213724e-06,
      "loss": 0.2748,
      "step": 19500
    },
    {
      "epoch": 7.330333708286465,
      "grad_norm": 0.06046580150723457,
      "learning_rate": 4.206505436820397e-06,
      "loss": 0.2085,
      "step": 19550
    },
    {
      "epoch": 7.349081364829396,
      "grad_norm": 9.024802207946777,
      "learning_rate": 4.0893325834270716e-06,
      "loss": 0.2,
      "step": 19600
    },
    {
      "epoch": 7.367829021372328,
      "grad_norm": 46.68151092529297,
      "learning_rate": 3.972159730033746e-06,
      "loss": 0.1435,
      "step": 19650
    },
    {
      "epoch": 7.386576677915261,
      "grad_norm": 3.999422550201416,
      "learning_rate": 3.85498687664042e-06,
      "loss": 0.2059,
      "step": 19700
    },
    {
      "epoch": 7.405324334458193,
      "grad_norm": 0.05996302142739296,
      "learning_rate": 3.7378140232470945e-06,
      "loss": 0.1744,
      "step": 19750
    },
    {
      "epoch": 7.424071991001125,
      "grad_norm": 0.0484611876308918,
      "learning_rate": 3.620641169853768e-06,
      "loss": 0.1848,
      "step": 19800
    },
    {
      "epoch": 7.442819647544057,
      "grad_norm": 2.8784148693084717,
      "learning_rate": 3.5034683164604427e-06,
      "loss": 0.1836,
      "step": 19850
    },
    {
      "epoch": 7.461567304086989,
      "grad_norm": 61.99333572387695,
      "learning_rate": 3.386295463067117e-06,
      "loss": 0.1872,
      "step": 19900
    },
    {
      "epoch": 7.480314960629921,
      "grad_norm": 5.853213310241699,
      "learning_rate": 3.269122609673791e-06,
      "loss": 0.2815,
      "step": 19950
    },
    {
      "epoch": 7.499062617172854,
      "grad_norm": 29.42198371887207,
      "learning_rate": 3.1519497562804652e-06,
      "loss": 0.1336,
      "step": 20000
    },
    {
      "epoch": 7.517810273715785,
      "grad_norm": 0.05262332782149315,
      "learning_rate": 3.034776902887139e-06,
      "loss": 0.2252,
      "step": 20050
    },
    {
      "epoch": 7.536557930258717,
      "grad_norm": 0.16348494589328766,
      "learning_rate": 2.9176040494938134e-06,
      "loss": 0.1272,
      "step": 20100
    },
    {
      "epoch": 7.55530558680165,
      "grad_norm": 42.102874755859375,
      "learning_rate": 2.8004311961004873e-06,
      "loss": 0.2245,
      "step": 20150
    },
    {
      "epoch": 7.574053243344582,
      "grad_norm": 9.747303009033203,
      "learning_rate": 2.683258342707162e-06,
      "loss": 0.1375,
      "step": 20200
    },
    {
      "epoch": 7.592800899887514,
      "grad_norm": 60.2206916809082,
      "learning_rate": 2.5684289463817023e-06,
      "loss": 0.2368,
      "step": 20250
    },
    {
      "epoch": 7.611548556430446,
      "grad_norm": 1.3230851888656616,
      "learning_rate": 2.4512560929883766e-06,
      "loss": 0.2882,
      "step": 20300
    },
    {
      "epoch": 7.630296212973378,
      "grad_norm": 1.075814127922058,
      "learning_rate": 2.334083239595051e-06,
      "loss": 0.2214,
      "step": 20350
    },
    {
      "epoch": 7.64904386951631,
      "grad_norm": 5.040122985839844,
      "learning_rate": 2.216910386201725e-06,
      "loss": 0.1225,
      "step": 20400
    },
    {
      "epoch": 7.667791526059243,
      "grad_norm": 0.01117820292711258,
      "learning_rate": 2.099737532808399e-06,
      "loss": 0.1499,
      "step": 20450
    },
    {
      "epoch": 7.686539182602175,
      "grad_norm": 0.04084312915802002,
      "learning_rate": 1.982564679415073e-06,
      "loss": 0.2251,
      "step": 20500
    },
    {
      "epoch": 7.705286839145106,
      "grad_norm": 0.10700350999832153,
      "learning_rate": 1.8653918260217475e-06,
      "loss": 0.2176,
      "step": 20550
    },
    {
      "epoch": 7.724034495688039,
      "grad_norm": 30.93014144897461,
      "learning_rate": 1.7482189726284216e-06,
      "loss": 0.2865,
      "step": 20600
    },
    {
      "epoch": 7.742782152230971,
      "grad_norm": 16.662235260009766,
      "learning_rate": 1.6310461192350957e-06,
      "loss": 0.2745,
      "step": 20650
    },
    {
      "epoch": 7.761529808773903,
      "grad_norm": 39.97982406616211,
      "learning_rate": 1.5138732658417698e-06,
      "loss": 0.2766,
      "step": 20700
    },
    {
      "epoch": 7.780277465316836,
      "grad_norm": 136.25730895996094,
      "learning_rate": 1.3967004124484441e-06,
      "loss": 0.2471,
      "step": 20750
    },
    {
      "epoch": 7.799025121859767,
      "grad_norm": 0.0388745479285717,
      "learning_rate": 1.2795275590551182e-06,
      "loss": 0.1954,
      "step": 20800
    },
    {
      "epoch": 7.817772778402699,
      "grad_norm": 37.43332290649414,
      "learning_rate": 1.1623547056617923e-06,
      "loss": 0.1944,
      "step": 20850
    },
    {
      "epoch": 7.836520434945632,
      "grad_norm": 71.24165344238281,
      "learning_rate": 1.0451818522684664e-06,
      "loss": 0.1492,
      "step": 20900
    },
    {
      "epoch": 7.855268091488564,
      "grad_norm": 18.100292205810547,
      "learning_rate": 9.280089988751405e-07,
      "loss": 0.1976,
      "step": 20950
    },
    {
      "epoch": 7.874015748031496,
      "grad_norm": 18.386987686157227,
      "learning_rate": 8.108361454818149e-07,
      "loss": 0.2631,
      "step": 21000
    },
    {
      "epoch": 7.892763404574428,
      "grad_norm": 89.09672546386719,
      "learning_rate": 6.93663292088489e-07,
      "loss": 0.2482,
      "step": 21050
    },
    {
      "epoch": 7.91151106111736,
      "grad_norm": 55.18645095825195,
      "learning_rate": 5.764904386951631e-07,
      "loss": 0.1737,
      "step": 21100
    },
    {
      "epoch": 7.930258717660292,
      "grad_norm": 30.565244674682617,
      "learning_rate": 4.5931758530183727e-07,
      "loss": 0.1683,
      "step": 21150
    },
    {
      "epoch": 7.949006374203225,
      "grad_norm": 32.08301544189453,
      "learning_rate": 3.4214473190851147e-07,
      "loss": 0.2459,
      "step": 21200
    },
    {
      "epoch": 7.967754030746157,
      "grad_norm": 60.01599884033203,
      "learning_rate": 2.2497187851518563e-07,
      "loss": 0.3078,
      "step": 21250
    },
    {
      "epoch": 7.986501687289088,
      "grad_norm": 44.181610107421875,
      "learning_rate": 1.0779902512185977e-07,
      "loss": 0.2478,
      "step": 21300
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9065,
      "eval_f1_score": 0.8603098957363916,
      "eval_loss": 0.369020938873291,
      "eval_runtime": 2.1133,
      "eval_samples_per_second": 946.375,
      "eval_steps_per_second": 158.045,
      "step": 21336
    }
  ],
  "logging_steps": 50,
  "max_steps": 21336,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 40706310144000.0,
  "train_batch_size": 6,
  "trial_name": null,
  "trial_params": null
}
